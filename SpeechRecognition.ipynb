{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilstahl97/Scalable-Machine-Learning-and-Deep-Learning-ID2223/blob/notebooks/SpeechRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72r5k4sECfZj"
      },
      "source": [
        "## Speech Emotion Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_MrfWn7CfZl"
      },
      "source": [
        "#### RAVDESS Dataset:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x0YmUqwCfZm"
      },
      "source": [
        "- The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) is licensed under CC BY-NA-SC 4.0. and can be downloaded free of charge at https://zenodo.org/record/1188976.\n",
        "- The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) contains 7356 files (total size: 24.8 GB). \n",
        "- The database contains 24 professional actors (12 female, 12 male), vocalizing two lexically-matched statements in a neutral North American accent. \n",
        "- Speech includes calm, happy, sad, angry, fearful, surprise, and disgust expressions, and song contains calm, happy, sad, angry, and fearful emotions. \n",
        "- Each expression is produced at two levels of emotional intensity (normal, strong), with an additional neutral expression. - All conditions are available in three modality formats: Audio-only (16bit, 48kHz .wav), Audio-Video (720p H.264, AAC 48kHz, .mp4), and Video-only (no sound).  \n",
        "\n",
        "For this analysis, the below file types have been used:\n",
        "- Audio speech files. \n",
        "- Additionally, the speech from the video files have been extracted by converting the MP4 files to WAV format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCwwIY3oCfZn"
      },
      "source": [
        "File naming convention: Each of the 7356 RAVDESS files has a unique filename. The filename consists of a 7-part numerical identifier (e.g., 02-01-06-01-02-01-12.mp4). These identifiers define the stimulus characteristics: \n",
        "\n",
        "Filename identifiers \n",
        "- Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "- Vocal channel (01 = speech, 02 = song).\n",
        "- Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
        "- Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "- Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "- Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "- Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# README - Execute this cell to mount the notebook in your google drive. \n",
        "# Execute the cell and follow the link to sign and, paste the given key in the little text box. The credentials are only available for you. \n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/audio-dataset\"):\n",
        "  print(\"Pulling dataset\")\n",
        "  os.makedirs(\"/content/drive/MyDrive/audio-dataset\")\n",
        "  !git clone https://github.com/emilstahl97/Audio-dataset.git\n",
        "else:\n",
        "  print(\"Dataset already exists\")\n",
        "\n",
        "os.chdir(\"/content/drive/MyDrive/audio-dataset\")\n",
        "#os.chdir(\"/content/drive/MyDrive/audio-dataset/Audio-dataset/Audio-dataset\")\n",
        "#os.chdir(\"/content/drive/MyDrive/audio-dataset/Audio-dataset/Rawdata\")\n",
        "\n",
        "!git pull\n",
        "!ls\n",
        "\n",
        "RAVDESS_PATH = \"./RAVDESS\"\n",
        "SAVEE_PATH = \"./SAVEE\"\n",
        "SAVED_MODELS_PATH = \"../saved_models\"\n",
        "\n",
        "if not os.path.exists(\"/content/drive/MyDrive/ID2223/project/mfcc\"):\n",
        "  os.makedirs(\"/content/drive/MyDrive/ID2223/project/mfcc/\")\n",
        "  \n",
        "if not os.path.exists(\"/content/drive/MyDrive/ID2223/project/emotion\"):\n",
        "  os.makedirs(\"/content/drive/MyDrive/ID2223/project/emotion/\")\n",
        "\n",
        "mfcc_file_path = \"/content/drive/MyDrive/ID2223/project/mfcc/mfcc.npy\"\n",
        "emotion_file_path = \"/content/drive/MyDrive/ID2223/project/emotion/emotion.npy\"\n",
        "path_AudioFiles = './RAVDESS'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t072N24D2lC",
        "outputId": "01e38e51-db93-4c12-bb38-1b553d35dfd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset already exists\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "RAVDESS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow_hub\n",
        "!pip install --upgrade tensorflow\n",
        "!pip install --upgrade keras\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade matplotlib\n",
        "!pip install --upgrade librosa\n",
        "!pip install --upgrade scipy\n",
        "!pip install --upgrade scikit-learn\n",
        "!pip install --upgrade pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "A498crVuC2oe",
        "outputId": "fcc2af2b-18e4-4206-fb57-e7c78b88f294"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.22.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (12.0.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.42.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.13.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
            "Collecting numpy\n",
            "  Downloading numpy-1.21.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 5.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.2 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.28.5-py3-none-any.whl (890 kB)\n",
            "\u001b[K     |████████████████████████████████| 890 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (21.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.6)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (7.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
            "Installing collected packages: fonttools, matplotlib\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed fonttools-4.28.5 matplotlib-3.5.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.5.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.21.5)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (3.0.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (2.23.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n",
            "Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->pooch>=1.0->librosa) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Collecting scipy\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.23.0,>=1.16.5 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.5)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.7.3\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.1)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.5)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.3.post1 requires numpy<1.20,>=1.16.0, but you have numpy 1.21.5 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-1.0.2\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Collecting pandas\n",
            "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.3 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.21.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed pandas-1.3.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qUuSd_z1CfZo"
      },
      "outputs": [],
      "source": [
        "# Import libraries \n",
        "import librosa\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from matplotlib.pyplot import specgram\n",
        "import pandas as pd\n",
        "import glob \n",
        "from sklearn.metrics import confusion_matrix\n",
        "import IPython.display as ipd  \n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import subprocess\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report,confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input, Flatten, Dropout, Activation, BatchNormalization\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras.models import Model\n",
        "\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZcPEqnzCfZu"
      },
      "source": [
        "### Explore the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SUCRoj90CfZ0"
      },
      "outputs": [],
      "source": [
        "# Define a function to generate MFCC from the audio files\n",
        "\n",
        "def fn_MFCC_Emotion(v_path_AudioFiles):\n",
        "    \"Feature Generation: MFCC and Emotion\"\n",
        "    print(\"in mfcc\")\n",
        "    i = 0\n",
        "    for path in [v_path_AudioFiles]:\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for name in files:\n",
        "                i = i + 1\n",
        "                print(name, i)\n",
        "\n",
        "                X, sample_rate = librosa.load(os.path.join(str(root),str(name)), res_type='kaiser_fast')  \n",
        "                v_mfcc = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0) \n",
        "\n",
        "                v_emotion = int(name[7:8]) - 1 \n",
        "                \n",
        "                lst_mfcc.append(v_mfcc)\n",
        "                lst_emotion.append(v_emotion)\n",
        "    return lst_mfcc, lst_emotion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "lst_mfcc = []\n",
        "lst_emotion = []\n",
        "mfcc = []\n",
        "emotion = []\n",
        "\n",
        "if not os.path.exists(mfcc_file_path) or not os.path.exists(emotion_file_path):\n",
        "    print(\"Running fn_MFCC_Emotion...\")\n",
        "    %time mfcc, emotion =  fn_MFCC_Emotion(path_AudioFiles)\n",
        "\n",
        "    print(mfcc[0:3], emotion[0:3])\n",
        "\n",
        "    np.save(mfcc_file_path, mfcc)\n",
        "    np.save(emotion_file_path, emotion)\n",
        "  \n",
        "  \n",
        "elif os.path.exists(mfcc_file_path) and os.path.exists(emotion_file_path):\n",
        "  print(\"Loading mfcc and emotion from local filesystem...\")\n",
        "  mfcc = np.load(mfcc_file_path, allow_pickle=True)\n",
        "  emotion = np.load(emotion_file_path, allow_pickle=True)\n",
        "\n",
        "X = np.array(mfcc)\n",
        "y = np.array(emotion)\n",
        "\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qs5AEpuNkV6",
        "outputId": "c00529e6-bf6b-477c-b34c-338c78c6dfcf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading mfcc and emotion from local filesystem...\n",
            "(2884, 40) (2884,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DZUoyJDVCfZ2"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esBtO3NxCfZ2"
      },
      "source": [
        "### Model 1: Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pvc5stgQCfZ3",
        "outputId": "d9aca9a0-bbbf-4523-88de-6e586b44beb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 220 ms, sys: 0 ns, total: 220 ms\n",
            "Wall time: 221 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf=3,\n",
              "                       random_state=9)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_leaf = 3, \n",
        "                                 random_state= 9)\n",
        "\n",
        "%time dt.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8S7ZSfoCfZ4",
        "outputId": "0ee853ae-874c-47af-a448-8088aadf4442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.66      0.64        59\n",
            "           1       0.69      0.71      0.70       119\n",
            "           2       0.53      0.58      0.56       133\n",
            "           3       0.45      0.62      0.52        89\n",
            "           4       0.66      0.71      0.68       106\n",
            "           5       0.73      0.61      0.66       132\n",
            "           6       0.62      0.49      0.55       117\n",
            "           7       0.50      0.47      0.48       111\n",
            "\n",
            "    accuracy                           0.60       866\n",
            "   macro avg       0.60      0.60      0.60       866\n",
            "weighted avg       0.61      0.60      0.60       866\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt.fit(X_train, y_train)\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzLFmZjuCfZ4"
      },
      "source": [
        "### Model 2: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aa2PYxeCfZ5",
        "outputId": "bee40e8c-b59b-4e08-eb59-9fc9eb4d02a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 58s, sys: 1.28 s, total: 2min 59s\n",
            "Wall time: 2min 59s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, max_features='sqrt', max_leaf_nodes=100,\n",
              "                       min_samples_leaf=3, min_samples_split=20,\n",
              "                       n_estimators=20000, random_state=9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "rf = RandomForestClassifier(criterion=\"gini\", max_depth=10, max_features=\"sqrt\", \n",
        "                                 max_leaf_nodes = 100, min_samples_leaf = 3, min_samples_split = 20, \n",
        "                                 n_estimators= 20000, random_state= 9)\n",
        "\n",
        "%time rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkDRkFQrCfZ5",
        "outputId": "f45b23f3-9dba-452b-c9f8-fd5f508f94eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.44      0.61        59\n",
            "           1       0.77      1.00      0.87       119\n",
            "           2       0.90      0.71      0.80       133\n",
            "           3       0.68      0.84      0.75        89\n",
            "           4       0.89      0.87      0.88       106\n",
            "           5       0.83      0.78      0.80       132\n",
            "           6       0.80      0.81      0.81       117\n",
            "           7       0.72      0.80      0.76       111\n",
            "\n",
            "    accuracy                           0.80       866\n",
            "   macro avg       0.82      0.78      0.78       866\n",
            "weighted avg       0.82      0.80      0.80       866\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aod5TPWFCfZ6"
      },
      "source": [
        "### Model 3: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4S6fvVtCfZ6",
        "outputId": "708403e2-12c2-4129-d937-bba880ceb166"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3min 43s, sys: 946 ms, total: 3min 44s\n",
            "Wall time: 3min 44s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(gamma=0.5, max_depth=10, n_estimators=2000,\n",
              "              objective='multi:softprob')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "XGB = XGBClassifier(n_estimators=2000, gamma=0.5,learning_rate=0.1, max_depth = 10)\n",
        "\n",
        "%time XGB.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTG8Iwq1CfZ7",
        "outputId": "da7e7f32-236f-4015-83c3-4f8d16b14f38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.73      0.81        59\n",
            "           1       0.91      0.97      0.93       119\n",
            "           2       0.91      0.92      0.92       133\n",
            "           3       0.81      0.98      0.89        89\n",
            "           4       0.91      0.92      0.92       106\n",
            "           5       0.89      0.88      0.89       132\n",
            "           6       0.94      0.88      0.91       117\n",
            "           7       0.86      0.80      0.83       111\n",
            "\n",
            "    accuracy                           0.89       866\n",
            "   macro avg       0.89      0.89      0.89       866\n",
            "weighted avg       0.90      0.89      0.89       866\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_pred = XGB.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhmlLj2LCfZ7"
      },
      "source": [
        "### Model 4: CNN (Convolutional  Neural Network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcAEWiymCfZ8",
        "outputId": "5f67327e-d851-41b4-f3b8-ee09d0c2773d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2018, 40, 1), (866, 40, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "X_train = np.expand_dims(X_train, axis=2)\n",
        "X_test = np.expand_dims(X_test, axis=2)\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r06kypHICfZ8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(256, 8, padding='same',input_shape=(X_train.shape[1],1))) \n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(256, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(128, 8, padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(MaxPooling1D(pool_size=(4)))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv1D(64, 8, padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(8)) \n",
        "model.add(Activation('softmax'))\n",
        "opt = optimizers.RMSprop(learning_rate=0.00001, decay=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z4YdLAzCfZ9",
        "outputId": "44c334ce-57ce-49c1-f0c3-e9882ab219bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 40, 256)           2304      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 40, 256)           0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 40, 256)           524544    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 40, 256)          1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 40, 256)           0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 40, 256)           0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 10, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 10, 128)           262272    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 10, 128)           131200    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 10, 128)           131200    \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 10, 128)           131200    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 10, 128)          512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10, 128)           0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10, 128)           0         \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPooling  (None, 2, 128)           0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_6 (Conv1D)           (None, 2, 64)             65600     \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 2, 64)             0         \n",
            "                                                                 \n",
            " conv1d_7 (Conv1D)           (None, 2, 64)             32832     \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 2, 64)             0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 1032      \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 8)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,283,720\n",
            "Trainable params: 1,282,952\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model):\n",
        "    import os\n",
        "    model_name = 'cnn.h5'\n",
        "    save_dir = os.path.join(os.getcwd(), \"/content/drive/MyDrive/savedmodels/\")\n",
        "    # Save model and weights\n",
        "    if not os.path.isdir(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "    model_path = os.path.join(save_dir, model_name)\n",
        "    model.save(model_path)\n",
        "    print('Saved trained model at %s ' % model_path)\n",
        "\n",
        "    model_json = model.to_json()\n",
        "    with open(\"/content/drive/MyDrive/savedmodels/model.json\", \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    # serialize weights to HDF5\n",
        "    model.save_weights(\"/content/drive/MyDrive/savedmodels/model.h5\")\n",
        "    print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "ZjVAiKumQRDZ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0w8zndPwCfZ-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.models import model_from_json\n",
        "\n",
        "if os.path.exists(\"/content/drive/MyDrive/savedmodels/cnn.h5\"):\n",
        "  print(\"Loading pre-trained model\")\n",
        "  model = keras.models.load_model(\"/content/drive/MyDrive/savedmodels/cnn.h5\")\n",
        "  json_file = open('/content/drive/MyDrive/savedmodels/model.json', 'r')\n",
        "  loaded_model_json = json_file.read()\n",
        "  json_file.close()\n",
        "  model = model_from_json(loaded_model_json)\n",
        "  # load weights into new model\n",
        "  model.load_weights(\"/content/drive/MyDrive/savedmodels/model.h5\")\n",
        "  print(\"Loaded model from disk\")\n",
        "#else:\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  %time cnn = model.fit(X_train, y_train, batch_size=1, epochs=2, validation_data=(X_test, y_test)) #should be bs 16 and 1000 epochs\n",
        "  save_model(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "iu5F6t7xCfZ_",
        "outputId": "d8624e3a-e49d-486e-b492-4cebef12d82c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-ed6eb6b1f6ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Plot the model loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cnn' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the model loss and accuracy \n",
        "plt.plot(cnn.history['loss'])\n",
        "plt.plot(cnn.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(cnn.history['accuracy'])\n",
        "plt.plot(cnn.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6aWp71vqCfaA"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "hshaHU-bCfaA",
        "outputId": "8a848fa8-fcd3-417a-cc0d-d7f4df4a19b2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-e7622b950e3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2108\u001b[0m     \"\"\"\n\u001b[1;32m   2109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2110\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2112\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "GrPVaH5ZCfaB",
        "outputId": "44c7128d-268d-4544-c2da-6e845c6058ff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-bf4066c99f71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m         raise ValueError(\n\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             )\n\u001b[1;32m     97\u001b[0m         )\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous-multioutput targets"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# 0 = neutral, 1 = calm, 2 = happy, 3 = sad, 4 = angry, 5 = fearful, 6 = disgust, 7 = surprised"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Build lstm model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
        "model.add(keras.layers.LSTM(64))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "model.add(keras.layers.Dense(8, activation='softmax'))"
      ],
      "metadata": {
        "id": "-teayQUDz-Le"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "optimiser = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "model.compile(optimizer=optimiser, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o824Bqd0LV4",
        "outputId": "c5432cf6-f8b6-41de-9e25-deebfdd15090"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 40, 64)            16896     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54,600\n",
            "Trainable params: 54,600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate model\n",
        "lstm = model.fit(X_train, y_train, batch_size=16, epochs=1000, validation_data=(X_test, y_test))\n",
        "loss, acc = model.evaluate(X_test, y_test, verbose=2)\n",
        "print('LSTM model test accuracy: ', acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yH1haSpo0amp",
        "outputId": "6be6be9d-3c97-4e9c-bd82-f90538ab52b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "127/127 [==============================] - 14s 72ms/step - loss: 2.0838 - accuracy: 0.1427 - val_loss: 2.0819 - val_accuracy: 0.1686\n",
            "Epoch 2/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0819 - accuracy: 0.1640 - val_loss: 2.0797 - val_accuracy: 0.1721\n",
            "Epoch 3/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 2.0802 - accuracy: 0.1482 - val_loss: 2.0778 - val_accuracy: 0.1767\n",
            "Epoch 4/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 2.0777 - accuracy: 0.1606 - val_loss: 2.0760 - val_accuracy: 0.1709\n",
            "Epoch 5/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 2.0741 - accuracy: 0.1601 - val_loss: 2.0742 - val_accuracy: 0.1778\n",
            "Epoch 6/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0731 - accuracy: 0.1601 - val_loss: 2.0726 - val_accuracy: 0.1801\n",
            "Epoch 7/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0719 - accuracy: 0.1640 - val_loss: 2.0711 - val_accuracy: 0.1721\n",
            "Epoch 8/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 2.0680 - accuracy: 0.1705 - val_loss: 2.0699 - val_accuracy: 0.1778\n",
            "Epoch 9/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 2.0689 - accuracy: 0.1724 - val_loss: 2.0685 - val_accuracy: 0.1790\n",
            "Epoch 10/1000\n",
            "127/127 [==============================] - 6s 47ms/step - loss: 2.0646 - accuracy: 0.1814 - val_loss: 2.0670 - val_accuracy: 0.1848\n",
            "Epoch 11/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0661 - accuracy: 0.1754 - val_loss: 2.0657 - val_accuracy: 0.1882\n",
            "Epoch 12/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 2.0638 - accuracy: 0.1769 - val_loss: 2.0644 - val_accuracy: 0.1848\n",
            "Epoch 13/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 2.0622 - accuracy: 0.1833 - val_loss: 2.0628 - val_accuracy: 0.1894\n",
            "Epoch 14/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 2.0609 - accuracy: 0.1873 - val_loss: 2.0614 - val_accuracy: 0.1917\n",
            "Epoch 15/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0602 - accuracy: 0.1764 - val_loss: 2.0601 - val_accuracy: 0.1928\n",
            "Epoch 16/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 2.0606 - accuracy: 0.1700 - val_loss: 2.0587 - val_accuracy: 0.1882\n",
            "Epoch 17/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 2.0556 - accuracy: 0.1898 - val_loss: 2.0571 - val_accuracy: 0.1859\n",
            "Epoch 18/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0555 - accuracy: 0.1863 - val_loss: 2.0555 - val_accuracy: 0.1894\n",
            "Epoch 19/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0536 - accuracy: 0.1923 - val_loss: 2.0538 - val_accuracy: 0.1848\n",
            "Epoch 20/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 2.0531 - accuracy: 0.1819 - val_loss: 2.0522 - val_accuracy: 0.1894\n",
            "Epoch 21/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0534 - accuracy: 0.1789 - val_loss: 2.0506 - val_accuracy: 0.1917\n",
            "Epoch 22/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 2.0480 - accuracy: 0.1972 - val_loss: 2.0489 - val_accuracy: 0.1917\n",
            "Epoch 23/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 2.0469 - accuracy: 0.1838 - val_loss: 2.0471 - val_accuracy: 0.1963\n",
            "Epoch 24/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0493 - accuracy: 0.1873 - val_loss: 2.0454 - val_accuracy: 0.1963\n",
            "Epoch 25/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0468 - accuracy: 0.1863 - val_loss: 2.0435 - val_accuracy: 0.1975\n",
            "Epoch 26/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 2.0434 - accuracy: 0.1972 - val_loss: 2.0417 - val_accuracy: 0.1986\n",
            "Epoch 27/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 2.0423 - accuracy: 0.1888 - val_loss: 2.0399 - val_accuracy: 0.2021\n",
            "Epoch 28/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 2.0437 - accuracy: 0.1918 - val_loss: 2.0382 - val_accuracy: 0.2032\n",
            "Epoch 29/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0394 - accuracy: 0.1938 - val_loss: 2.0362 - val_accuracy: 0.2079\n",
            "Epoch 30/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 2.0347 - accuracy: 0.2096 - val_loss: 2.0339 - val_accuracy: 0.2079\n",
            "Epoch 31/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 2.0326 - accuracy: 0.2091 - val_loss: 2.0315 - val_accuracy: 0.2079\n",
            "Epoch 32/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 2.0315 - accuracy: 0.2017 - val_loss: 2.0292 - val_accuracy: 0.2067\n",
            "Epoch 33/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 2.0295 - accuracy: 0.2042 - val_loss: 2.0264 - val_accuracy: 0.2125\n",
            "Epoch 34/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 2.0263 - accuracy: 0.2126 - val_loss: 2.0238 - val_accuracy: 0.2159\n",
            "Epoch 35/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0261 - accuracy: 0.2096 - val_loss: 2.0210 - val_accuracy: 0.2171\n",
            "Epoch 36/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 2.0243 - accuracy: 0.2047 - val_loss: 2.0180 - val_accuracy: 0.2171\n",
            "Epoch 37/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0170 - accuracy: 0.2195 - val_loss: 2.0146 - val_accuracy: 0.2206\n",
            "Epoch 38/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 2.0143 - accuracy: 0.2086 - val_loss: 2.0114 - val_accuracy: 0.2275\n",
            "Epoch 39/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0129 - accuracy: 0.2205 - val_loss: 2.0078 - val_accuracy: 0.2286\n",
            "Epoch 40/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 2.0106 - accuracy: 0.2279 - val_loss: 2.0047 - val_accuracy: 0.2286\n",
            "Epoch 41/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 2.0036 - accuracy: 0.2230 - val_loss: 2.0004 - val_accuracy: 0.2333\n",
            "Epoch 42/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0046 - accuracy: 0.2225 - val_loss: 1.9963 - val_accuracy: 0.2356\n",
            "Epoch 43/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 2.0013 - accuracy: 0.2185 - val_loss: 1.9921 - val_accuracy: 0.2321\n",
            "Epoch 44/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.9882 - accuracy: 0.2230 - val_loss: 1.9879 - val_accuracy: 0.2321\n",
            "Epoch 45/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.9889 - accuracy: 0.2250 - val_loss: 1.9838 - val_accuracy: 0.2344\n",
            "Epoch 46/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.9800 - accuracy: 0.2250 - val_loss: 1.9791 - val_accuracy: 0.2356\n",
            "Epoch 47/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.9812 - accuracy: 0.2215 - val_loss: 1.9743 - val_accuracy: 0.2402\n",
            "Epoch 48/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.9865 - accuracy: 0.2210 - val_loss: 1.9697 - val_accuracy: 0.2390\n",
            "Epoch 49/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.9731 - accuracy: 0.2349 - val_loss: 1.9652 - val_accuracy: 0.2402\n",
            "Epoch 50/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.9754 - accuracy: 0.2265 - val_loss: 1.9606 - val_accuracy: 0.2494\n",
            "Epoch 51/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9640 - accuracy: 0.2304 - val_loss: 1.9557 - val_accuracy: 0.2552\n",
            "Epoch 52/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.9625 - accuracy: 0.2334 - val_loss: 1.9511 - val_accuracy: 0.2564\n",
            "Epoch 53/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.9674 - accuracy: 0.2359 - val_loss: 1.9468 - val_accuracy: 0.2610\n",
            "Epoch 54/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9628 - accuracy: 0.2413 - val_loss: 1.9427 - val_accuracy: 0.2552\n",
            "Epoch 55/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.9549 - accuracy: 0.2314 - val_loss: 1.9381 - val_accuracy: 0.2598\n",
            "Epoch 56/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.9476 - accuracy: 0.2166 - val_loss: 1.9343 - val_accuracy: 0.2587\n",
            "Epoch 57/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9483 - accuracy: 0.2438 - val_loss: 1.9302 - val_accuracy: 0.2598\n",
            "Epoch 58/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9452 - accuracy: 0.2448 - val_loss: 1.9261 - val_accuracy: 0.2633\n",
            "Epoch 59/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.9413 - accuracy: 0.2438 - val_loss: 1.9223 - val_accuracy: 0.2737\n",
            "Epoch 60/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.9433 - accuracy: 0.2354 - val_loss: 1.9193 - val_accuracy: 0.2806\n",
            "Epoch 61/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.9414 - accuracy: 0.2389 - val_loss: 1.9169 - val_accuracy: 0.2794\n",
            "Epoch 62/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.9352 - accuracy: 0.2458 - val_loss: 1.9125 - val_accuracy: 0.2771\n",
            "Epoch 63/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.9377 - accuracy: 0.2458 - val_loss: 1.9102 - val_accuracy: 0.2760\n",
            "Epoch 64/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.9229 - accuracy: 0.2582 - val_loss: 1.9067 - val_accuracy: 0.2852\n",
            "Epoch 65/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.9288 - accuracy: 0.2502 - val_loss: 1.9035 - val_accuracy: 0.2887\n",
            "Epoch 66/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.9266 - accuracy: 0.2542 - val_loss: 1.9007 - val_accuracy: 0.2864\n",
            "Epoch 67/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.9215 - accuracy: 0.2418 - val_loss: 1.8974 - val_accuracy: 0.2864\n",
            "Epoch 68/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.9279 - accuracy: 0.2562 - val_loss: 1.8953 - val_accuracy: 0.2898\n",
            "Epoch 69/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.9205 - accuracy: 0.2592 - val_loss: 1.8924 - val_accuracy: 0.2818\n",
            "Epoch 70/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9088 - accuracy: 0.2602 - val_loss: 1.8899 - val_accuracy: 0.2841\n",
            "Epoch 71/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.9138 - accuracy: 0.2522 - val_loss: 1.8882 - val_accuracy: 0.2852\n",
            "Epoch 72/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.9230 - accuracy: 0.2636 - val_loss: 1.8855 - val_accuracy: 0.2887\n",
            "Epoch 73/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.9125 - accuracy: 0.2597 - val_loss: 1.8832 - val_accuracy: 0.2841\n",
            "Epoch 74/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.9027 - accuracy: 0.2656 - val_loss: 1.8811 - val_accuracy: 0.2910\n",
            "Epoch 75/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.9025 - accuracy: 0.2701 - val_loss: 1.8791 - val_accuracy: 0.2887\n",
            "Epoch 76/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.9010 - accuracy: 0.2646 - val_loss: 1.8764 - val_accuracy: 0.2898\n",
            "Epoch 77/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.9045 - accuracy: 0.2696 - val_loss: 1.8741 - val_accuracy: 0.2898\n",
            "Epoch 78/1000\n",
            "127/127 [==============================] - 8s 67ms/step - loss: 1.8902 - accuracy: 0.2770 - val_loss: 1.8721 - val_accuracy: 0.2910\n",
            "Epoch 79/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8973 - accuracy: 0.2567 - val_loss: 1.8695 - val_accuracy: 0.3014\n",
            "Epoch 80/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.9026 - accuracy: 0.2592 - val_loss: 1.8678 - val_accuracy: 0.3025\n",
            "Epoch 81/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.8965 - accuracy: 0.2626 - val_loss: 1.8655 - val_accuracy: 0.3014\n",
            "Epoch 82/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8936 - accuracy: 0.2676 - val_loss: 1.8639 - val_accuracy: 0.3083\n",
            "Epoch 83/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.8967 - accuracy: 0.2666 - val_loss: 1.8620 - val_accuracy: 0.3083\n",
            "Epoch 84/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8874 - accuracy: 0.2755 - val_loss: 1.8604 - val_accuracy: 0.3083\n",
            "Epoch 85/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.8948 - accuracy: 0.2671 - val_loss: 1.8584 - val_accuracy: 0.3095\n",
            "Epoch 86/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.8868 - accuracy: 0.2755 - val_loss: 1.8566 - val_accuracy: 0.3118\n",
            "Epoch 87/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.8765 - accuracy: 0.2696 - val_loss: 1.8550 - val_accuracy: 0.3095\n",
            "Epoch 88/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8831 - accuracy: 0.2765 - val_loss: 1.8524 - val_accuracy: 0.3083\n",
            "Epoch 89/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.8770 - accuracy: 0.2820 - val_loss: 1.8515 - val_accuracy: 0.3106\n",
            "Epoch 90/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8872 - accuracy: 0.2770 - val_loss: 1.8489 - val_accuracy: 0.3129\n",
            "Epoch 91/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.8836 - accuracy: 0.2765 - val_loss: 1.8480 - val_accuracy: 0.3164\n",
            "Epoch 92/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8700 - accuracy: 0.2874 - val_loss: 1.8454 - val_accuracy: 0.3141\n",
            "Epoch 93/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8681 - accuracy: 0.3008 - val_loss: 1.8431 - val_accuracy: 0.3152\n",
            "Epoch 94/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.8691 - accuracy: 0.2834 - val_loss: 1.8415 - val_accuracy: 0.3210\n",
            "Epoch 95/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8667 - accuracy: 0.2770 - val_loss: 1.8402 - val_accuracy: 0.3176\n",
            "Epoch 96/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8742 - accuracy: 0.2859 - val_loss: 1.8379 - val_accuracy: 0.3187\n",
            "Epoch 97/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.8668 - accuracy: 0.2953 - val_loss: 1.8361 - val_accuracy: 0.3176\n",
            "Epoch 98/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8613 - accuracy: 0.2785 - val_loss: 1.8343 - val_accuracy: 0.3222\n",
            "Epoch 99/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8645 - accuracy: 0.2889 - val_loss: 1.8328 - val_accuracy: 0.3187\n",
            "Epoch 100/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.8675 - accuracy: 0.2790 - val_loss: 1.8320 - val_accuracy: 0.3210\n",
            "Epoch 101/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.8599 - accuracy: 0.2830 - val_loss: 1.8291 - val_accuracy: 0.3199\n",
            "Epoch 102/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8683 - accuracy: 0.2770 - val_loss: 1.8278 - val_accuracy: 0.3164\n",
            "Epoch 103/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.8599 - accuracy: 0.2958 - val_loss: 1.8267 - val_accuracy: 0.3152\n",
            "Epoch 104/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.8778 - accuracy: 0.2765 - val_loss: 1.8248 - val_accuracy: 0.3222\n",
            "Epoch 105/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.8440 - accuracy: 0.3003 - val_loss: 1.8235 - val_accuracy: 0.3176\n",
            "Epoch 106/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8517 - accuracy: 0.2968 - val_loss: 1.8214 - val_accuracy: 0.3187\n",
            "Epoch 107/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8558 - accuracy: 0.2874 - val_loss: 1.8192 - val_accuracy: 0.3187\n",
            "Epoch 108/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.8536 - accuracy: 0.2998 - val_loss: 1.8177 - val_accuracy: 0.3187\n",
            "Epoch 109/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.8527 - accuracy: 0.2849 - val_loss: 1.8161 - val_accuracy: 0.3199\n",
            "Epoch 110/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8452 - accuracy: 0.2889 - val_loss: 1.8143 - val_accuracy: 0.3222\n",
            "Epoch 111/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8533 - accuracy: 0.2998 - val_loss: 1.8133 - val_accuracy: 0.3233\n",
            "Epoch 112/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8511 - accuracy: 0.2914 - val_loss: 1.8112 - val_accuracy: 0.3314\n",
            "Epoch 113/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8425 - accuracy: 0.3038 - val_loss: 1.8102 - val_accuracy: 0.3222\n",
            "Epoch 114/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8475 - accuracy: 0.3053 - val_loss: 1.8086 - val_accuracy: 0.3268\n",
            "Epoch 115/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8488 - accuracy: 0.2968 - val_loss: 1.8073 - val_accuracy: 0.3233\n",
            "Epoch 116/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.8531 - accuracy: 0.2934 - val_loss: 1.8060 - val_accuracy: 0.3256\n",
            "Epoch 117/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.8401 - accuracy: 0.3057 - val_loss: 1.8046 - val_accuracy: 0.3291\n",
            "Epoch 118/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8361 - accuracy: 0.2978 - val_loss: 1.8029 - val_accuracy: 0.3383\n",
            "Epoch 119/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8355 - accuracy: 0.3077 - val_loss: 1.8015 - val_accuracy: 0.3372\n",
            "Epoch 120/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8473 - accuracy: 0.2944 - val_loss: 1.8004 - val_accuracy: 0.3349\n",
            "Epoch 121/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8272 - accuracy: 0.3062 - val_loss: 1.7984 - val_accuracy: 0.3337\n",
            "Epoch 122/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.8340 - accuracy: 0.3033 - val_loss: 1.7968 - val_accuracy: 0.3383\n",
            "Epoch 123/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8253 - accuracy: 0.3003 - val_loss: 1.7946 - val_accuracy: 0.3453\n",
            "Epoch 124/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8269 - accuracy: 0.3013 - val_loss: 1.7932 - val_accuracy: 0.3406\n",
            "Epoch 125/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8324 - accuracy: 0.2988 - val_loss: 1.7921 - val_accuracy: 0.3383\n",
            "Epoch 126/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.8323 - accuracy: 0.2973 - val_loss: 1.7913 - val_accuracy: 0.3395\n",
            "Epoch 127/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8311 - accuracy: 0.3028 - val_loss: 1.7896 - val_accuracy: 0.3430\n",
            "Epoch 128/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.8310 - accuracy: 0.2958 - val_loss: 1.7889 - val_accuracy: 0.3372\n",
            "Epoch 129/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8258 - accuracy: 0.2909 - val_loss: 1.7866 - val_accuracy: 0.3395\n",
            "Epoch 130/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8346 - accuracy: 0.2963 - val_loss: 1.7867 - val_accuracy: 0.3395\n",
            "Epoch 131/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8208 - accuracy: 0.3127 - val_loss: 1.7843 - val_accuracy: 0.3441\n",
            "Epoch 132/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.8127 - accuracy: 0.3102 - val_loss: 1.7821 - val_accuracy: 0.3453\n",
            "Epoch 133/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.8190 - accuracy: 0.3003 - val_loss: 1.7816 - val_accuracy: 0.3464\n",
            "Epoch 134/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.8128 - accuracy: 0.3127 - val_loss: 1.7789 - val_accuracy: 0.3487\n",
            "Epoch 135/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.8214 - accuracy: 0.2904 - val_loss: 1.7777 - val_accuracy: 0.3464\n",
            "Epoch 136/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.8119 - accuracy: 0.3117 - val_loss: 1.7763 - val_accuracy: 0.3476\n",
            "Epoch 137/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8088 - accuracy: 0.3152 - val_loss: 1.7754 - val_accuracy: 0.3464\n",
            "Epoch 138/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.8045 - accuracy: 0.3196 - val_loss: 1.7737 - val_accuracy: 0.3476\n",
            "Epoch 139/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.8109 - accuracy: 0.3162 - val_loss: 1.7721 - val_accuracy: 0.3510\n",
            "Epoch 140/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8054 - accuracy: 0.3147 - val_loss: 1.7710 - val_accuracy: 0.3476\n",
            "Epoch 141/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.8080 - accuracy: 0.3157 - val_loss: 1.7699 - val_accuracy: 0.3510\n",
            "Epoch 142/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8065 - accuracy: 0.3196 - val_loss: 1.7691 - val_accuracy: 0.3557\n",
            "Epoch 143/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.8035 - accuracy: 0.3152 - val_loss: 1.7660 - val_accuracy: 0.3476\n",
            "Epoch 144/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.8053 - accuracy: 0.3186 - val_loss: 1.7646 - val_accuracy: 0.3510\n",
            "Epoch 145/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.8026 - accuracy: 0.3162 - val_loss: 1.7634 - val_accuracy: 0.3487\n",
            "Epoch 146/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.8030 - accuracy: 0.3157 - val_loss: 1.7610 - val_accuracy: 0.3476\n",
            "Epoch 147/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.7984 - accuracy: 0.3147 - val_loss: 1.7604 - val_accuracy: 0.3522\n",
            "Epoch 148/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.7912 - accuracy: 0.3251 - val_loss: 1.7581 - val_accuracy: 0.3487\n",
            "Epoch 149/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.7955 - accuracy: 0.3181 - val_loss: 1.7563 - val_accuracy: 0.3522\n",
            "Epoch 150/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.7898 - accuracy: 0.3157 - val_loss: 1.7549 - val_accuracy: 0.3464\n",
            "Epoch 151/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.8018 - accuracy: 0.3201 - val_loss: 1.7541 - val_accuracy: 0.3464\n",
            "Epoch 152/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.7913 - accuracy: 0.3147 - val_loss: 1.7522 - val_accuracy: 0.3580\n",
            "Epoch 153/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7932 - accuracy: 0.3216 - val_loss: 1.7504 - val_accuracy: 0.3510\n",
            "Epoch 154/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7787 - accuracy: 0.3454 - val_loss: 1.7488 - val_accuracy: 0.3568\n",
            "Epoch 155/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7814 - accuracy: 0.3320 - val_loss: 1.7471 - val_accuracy: 0.3522\n",
            "Epoch 156/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7832 - accuracy: 0.3325 - val_loss: 1.7464 - val_accuracy: 0.3580\n",
            "Epoch 157/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7843 - accuracy: 0.3320 - val_loss: 1.7445 - val_accuracy: 0.3533\n",
            "Epoch 158/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.7784 - accuracy: 0.3285 - val_loss: 1.7421 - val_accuracy: 0.3510\n",
            "Epoch 159/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7746 - accuracy: 0.3251 - val_loss: 1.7400 - val_accuracy: 0.3533\n",
            "Epoch 160/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.7750 - accuracy: 0.3226 - val_loss: 1.7390 - val_accuracy: 0.3557\n",
            "Epoch 161/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7824 - accuracy: 0.3251 - val_loss: 1.7367 - val_accuracy: 0.3557\n",
            "Epoch 162/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7754 - accuracy: 0.3191 - val_loss: 1.7357 - val_accuracy: 0.3591\n",
            "Epoch 163/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7668 - accuracy: 0.3276 - val_loss: 1.7331 - val_accuracy: 0.3557\n",
            "Epoch 164/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.7800 - accuracy: 0.3201 - val_loss: 1.7314 - val_accuracy: 0.3580\n",
            "Epoch 165/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.7694 - accuracy: 0.3246 - val_loss: 1.7290 - val_accuracy: 0.3637\n",
            "Epoch 166/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7693 - accuracy: 0.3231 - val_loss: 1.7271 - val_accuracy: 0.3614\n",
            "Epoch 167/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.7686 - accuracy: 0.3295 - val_loss: 1.7272 - val_accuracy: 0.3626\n",
            "Epoch 168/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7687 - accuracy: 0.3236 - val_loss: 1.7252 - val_accuracy: 0.3557\n",
            "Epoch 169/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.7804 - accuracy: 0.3365 - val_loss: 1.7235 - val_accuracy: 0.3557\n",
            "Epoch 170/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.7641 - accuracy: 0.3226 - val_loss: 1.7207 - val_accuracy: 0.3672\n",
            "Epoch 171/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.7535 - accuracy: 0.3479 - val_loss: 1.7202 - val_accuracy: 0.3649\n",
            "Epoch 172/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7540 - accuracy: 0.3290 - val_loss: 1.7181 - val_accuracy: 0.3672\n",
            "Epoch 173/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.7474 - accuracy: 0.3330 - val_loss: 1.7154 - val_accuracy: 0.3695\n",
            "Epoch 174/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7557 - accuracy: 0.3280 - val_loss: 1.7145 - val_accuracy: 0.3661\n",
            "Epoch 175/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7555 - accuracy: 0.3340 - val_loss: 1.7135 - val_accuracy: 0.3637\n",
            "Epoch 176/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.7530 - accuracy: 0.3350 - val_loss: 1.7128 - val_accuracy: 0.3614\n",
            "Epoch 177/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.7431 - accuracy: 0.3360 - val_loss: 1.7099 - val_accuracy: 0.3672\n",
            "Epoch 178/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.7414 - accuracy: 0.3454 - val_loss: 1.7084 - val_accuracy: 0.3684\n",
            "Epoch 179/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7458 - accuracy: 0.3340 - val_loss: 1.7086 - val_accuracy: 0.3718\n",
            "Epoch 180/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.7335 - accuracy: 0.3424 - val_loss: 1.7089 - val_accuracy: 0.3695\n",
            "Epoch 181/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.7459 - accuracy: 0.3513 - val_loss: 1.7051 - val_accuracy: 0.3661\n",
            "Epoch 182/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7440 - accuracy: 0.3365 - val_loss: 1.7029 - val_accuracy: 0.3649\n",
            "Epoch 183/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.7410 - accuracy: 0.3419 - val_loss: 1.7018 - val_accuracy: 0.3649\n",
            "Epoch 184/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7370 - accuracy: 0.3538 - val_loss: 1.7010 - val_accuracy: 0.3707\n",
            "Epoch 185/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7499 - accuracy: 0.3271 - val_loss: 1.6999 - val_accuracy: 0.3672\n",
            "Epoch 186/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.7310 - accuracy: 0.3404 - val_loss: 1.6972 - val_accuracy: 0.3661\n",
            "Epoch 187/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7353 - accuracy: 0.3370 - val_loss: 1.6994 - val_accuracy: 0.3695\n",
            "Epoch 188/1000\n",
            "127/127 [==============================] - 9s 71ms/step - loss: 1.7361 - accuracy: 0.3414 - val_loss: 1.6951 - val_accuracy: 0.3672\n",
            "Epoch 189/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.7409 - accuracy: 0.3399 - val_loss: 1.6940 - val_accuracy: 0.3684\n",
            "Epoch 190/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.7356 - accuracy: 0.3494 - val_loss: 1.6929 - val_accuracy: 0.3730\n",
            "Epoch 191/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7342 - accuracy: 0.3394 - val_loss: 1.6918 - val_accuracy: 0.3707\n",
            "Epoch 192/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.7343 - accuracy: 0.3449 - val_loss: 1.6906 - val_accuracy: 0.3695\n",
            "Epoch 193/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7258 - accuracy: 0.3439 - val_loss: 1.6884 - val_accuracy: 0.3788\n",
            "Epoch 194/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.7173 - accuracy: 0.3404 - val_loss: 1.6872 - val_accuracy: 0.3684\n",
            "Epoch 195/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7266 - accuracy: 0.3409 - val_loss: 1.6858 - val_accuracy: 0.3707\n",
            "Epoch 196/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.7252 - accuracy: 0.3419 - val_loss: 1.6858 - val_accuracy: 0.3753\n",
            "Epoch 197/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.7246 - accuracy: 0.3677 - val_loss: 1.6855 - val_accuracy: 0.3730\n",
            "Epoch 198/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.7171 - accuracy: 0.3543 - val_loss: 1.6826 - val_accuracy: 0.3753\n",
            "Epoch 199/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7205 - accuracy: 0.3494 - val_loss: 1.6847 - val_accuracy: 0.3626\n",
            "Epoch 200/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.7134 - accuracy: 0.3647 - val_loss: 1.6814 - val_accuracy: 0.3637\n",
            "Epoch 201/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7234 - accuracy: 0.3469 - val_loss: 1.6846 - val_accuracy: 0.3764\n",
            "Epoch 202/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.7159 - accuracy: 0.3424 - val_loss: 1.6786 - val_accuracy: 0.3788\n",
            "Epoch 203/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.7136 - accuracy: 0.3499 - val_loss: 1.6784 - val_accuracy: 0.3707\n",
            "Epoch 204/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.7206 - accuracy: 0.3355 - val_loss: 1.6752 - val_accuracy: 0.3753\n",
            "Epoch 205/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.7152 - accuracy: 0.3494 - val_loss: 1.6762 - val_accuracy: 0.3718\n",
            "Epoch 206/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.7092 - accuracy: 0.3474 - val_loss: 1.6739 - val_accuracy: 0.3799\n",
            "Epoch 207/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.7103 - accuracy: 0.3434 - val_loss: 1.6722 - val_accuracy: 0.3788\n",
            "Epoch 208/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6975 - accuracy: 0.3612 - val_loss: 1.6698 - val_accuracy: 0.3730\n",
            "Epoch 209/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6943 - accuracy: 0.3499 - val_loss: 1.6692 - val_accuracy: 0.3684\n",
            "Epoch 210/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.7000 - accuracy: 0.3608 - val_loss: 1.6677 - val_accuracy: 0.3764\n",
            "Epoch 211/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.7092 - accuracy: 0.3484 - val_loss: 1.6672 - val_accuracy: 0.3707\n",
            "Epoch 212/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6929 - accuracy: 0.3518 - val_loss: 1.6666 - val_accuracy: 0.3764\n",
            "Epoch 213/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.7070 - accuracy: 0.3454 - val_loss: 1.6639 - val_accuracy: 0.3753\n",
            "Epoch 214/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.6955 - accuracy: 0.3593 - val_loss: 1.6636 - val_accuracy: 0.3753\n",
            "Epoch 215/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6945 - accuracy: 0.3622 - val_loss: 1.6625 - val_accuracy: 0.3730\n",
            "Epoch 216/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.7045 - accuracy: 0.3563 - val_loss: 1.6605 - val_accuracy: 0.3776\n",
            "Epoch 217/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6923 - accuracy: 0.3568 - val_loss: 1.6590 - val_accuracy: 0.3730\n",
            "Epoch 218/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6954 - accuracy: 0.3494 - val_loss: 1.6587 - val_accuracy: 0.3788\n",
            "Epoch 219/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.7013 - accuracy: 0.3449 - val_loss: 1.6578 - val_accuracy: 0.3799\n",
            "Epoch 220/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6872 - accuracy: 0.3603 - val_loss: 1.6578 - val_accuracy: 0.3741\n",
            "Epoch 221/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.6845 - accuracy: 0.3612 - val_loss: 1.6537 - val_accuracy: 0.3776\n",
            "Epoch 222/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6912 - accuracy: 0.3682 - val_loss: 1.6527 - val_accuracy: 0.3776\n",
            "Epoch 223/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6942 - accuracy: 0.3583 - val_loss: 1.6510 - val_accuracy: 0.3799\n",
            "Epoch 224/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6902 - accuracy: 0.3647 - val_loss: 1.6496 - val_accuracy: 0.3845\n",
            "Epoch 225/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6892 - accuracy: 0.3503 - val_loss: 1.6500 - val_accuracy: 0.3764\n",
            "Epoch 226/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6768 - accuracy: 0.3543 - val_loss: 1.6482 - val_accuracy: 0.3753\n",
            "Epoch 227/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6862 - accuracy: 0.3513 - val_loss: 1.6468 - val_accuracy: 0.3834\n",
            "Epoch 228/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6845 - accuracy: 0.3598 - val_loss: 1.6449 - val_accuracy: 0.3857\n",
            "Epoch 229/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.6783 - accuracy: 0.3479 - val_loss: 1.6445 - val_accuracy: 0.3857\n",
            "Epoch 230/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.6812 - accuracy: 0.3568 - val_loss: 1.6461 - val_accuracy: 0.3880\n",
            "Epoch 231/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6787 - accuracy: 0.3573 - val_loss: 1.6423 - val_accuracy: 0.3880\n",
            "Epoch 232/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.6741 - accuracy: 0.3632 - val_loss: 1.6436 - val_accuracy: 0.3764\n",
            "Epoch 233/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6768 - accuracy: 0.3499 - val_loss: 1.6400 - val_accuracy: 0.3880\n",
            "Epoch 234/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.6787 - accuracy: 0.3617 - val_loss: 1.6381 - val_accuracy: 0.3915\n",
            "Epoch 235/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6688 - accuracy: 0.3697 - val_loss: 1.6384 - val_accuracy: 0.3845\n",
            "Epoch 236/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6827 - accuracy: 0.3583 - val_loss: 1.6359 - val_accuracy: 0.3868\n",
            "Epoch 237/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.6714 - accuracy: 0.3622 - val_loss: 1.6347 - val_accuracy: 0.4007\n",
            "Epoch 238/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6624 - accuracy: 0.3766 - val_loss: 1.6342 - val_accuracy: 0.3961\n",
            "Epoch 239/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6687 - accuracy: 0.3642 - val_loss: 1.6344 - val_accuracy: 0.3845\n",
            "Epoch 240/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6667 - accuracy: 0.3583 - val_loss: 1.6311 - val_accuracy: 0.3915\n",
            "Epoch 241/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6758 - accuracy: 0.3593 - val_loss: 1.6320 - val_accuracy: 0.3845\n",
            "Epoch 242/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6637 - accuracy: 0.3652 - val_loss: 1.6327 - val_accuracy: 0.3845\n",
            "Epoch 243/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.6594 - accuracy: 0.3642 - val_loss: 1.6281 - val_accuracy: 0.3903\n",
            "Epoch 244/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.6596 - accuracy: 0.3667 - val_loss: 1.6285 - val_accuracy: 0.3868\n",
            "Epoch 245/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6756 - accuracy: 0.3598 - val_loss: 1.6260 - val_accuracy: 0.3984\n",
            "Epoch 246/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6519 - accuracy: 0.3726 - val_loss: 1.6260 - val_accuracy: 0.3903\n",
            "Epoch 247/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6557 - accuracy: 0.3707 - val_loss: 1.6277 - val_accuracy: 0.3880\n",
            "Epoch 248/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6516 - accuracy: 0.3657 - val_loss: 1.6252 - val_accuracy: 0.3961\n",
            "Epoch 249/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.6557 - accuracy: 0.3637 - val_loss: 1.6223 - val_accuracy: 0.3961\n",
            "Epoch 250/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6662 - accuracy: 0.3563 - val_loss: 1.6249 - val_accuracy: 0.3903\n",
            "Epoch 251/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6614 - accuracy: 0.3622 - val_loss: 1.6199 - val_accuracy: 0.3938\n",
            "Epoch 252/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.6591 - accuracy: 0.3608 - val_loss: 1.6198 - val_accuracy: 0.3926\n",
            "Epoch 253/1000\n",
            "127/127 [==============================] - 9s 71ms/step - loss: 1.6424 - accuracy: 0.3786 - val_loss: 1.6191 - val_accuracy: 0.3891\n",
            "Epoch 254/1000\n",
            "127/127 [==============================] - 8s 67ms/step - loss: 1.6502 - accuracy: 0.3741 - val_loss: 1.6188 - val_accuracy: 0.3938\n",
            "Epoch 255/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.6464 - accuracy: 0.3746 - val_loss: 1.6202 - val_accuracy: 0.3880\n",
            "Epoch 256/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.6493 - accuracy: 0.3761 - val_loss: 1.6180 - val_accuracy: 0.3891\n",
            "Epoch 257/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.6475 - accuracy: 0.3617 - val_loss: 1.6200 - val_accuracy: 0.3834\n",
            "Epoch 258/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6399 - accuracy: 0.3717 - val_loss: 1.6155 - val_accuracy: 0.3891\n",
            "Epoch 259/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6518 - accuracy: 0.3662 - val_loss: 1.6128 - val_accuracy: 0.4018\n",
            "Epoch 260/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6374 - accuracy: 0.3835 - val_loss: 1.6108 - val_accuracy: 0.4018\n",
            "Epoch 261/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6575 - accuracy: 0.3791 - val_loss: 1.6119 - val_accuracy: 0.3995\n",
            "Epoch 262/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6330 - accuracy: 0.3776 - val_loss: 1.6134 - val_accuracy: 0.4018\n",
            "Epoch 263/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.6369 - accuracy: 0.3751 - val_loss: 1.6208 - val_accuracy: 0.3891\n",
            "Epoch 264/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.6335 - accuracy: 0.3707 - val_loss: 1.6089 - val_accuracy: 0.4042\n",
            "Epoch 265/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.6444 - accuracy: 0.3736 - val_loss: 1.6130 - val_accuracy: 0.3903\n",
            "Epoch 266/1000\n",
            "127/127 [==============================] - 10s 76ms/step - loss: 1.6351 - accuracy: 0.3776 - val_loss: 1.6082 - val_accuracy: 0.4018\n",
            "Epoch 267/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6327 - accuracy: 0.3890 - val_loss: 1.6074 - val_accuracy: 0.3880\n",
            "Epoch 268/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6403 - accuracy: 0.3687 - val_loss: 1.6037 - val_accuracy: 0.3949\n",
            "Epoch 269/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6336 - accuracy: 0.3776 - val_loss: 1.6064 - val_accuracy: 0.3915\n",
            "Epoch 270/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.6289 - accuracy: 0.3781 - val_loss: 1.6015 - val_accuracy: 0.4053\n",
            "Epoch 271/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.6287 - accuracy: 0.3746 - val_loss: 1.6098 - val_accuracy: 0.3857\n",
            "Epoch 272/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6377 - accuracy: 0.3736 - val_loss: 1.6040 - val_accuracy: 0.4030\n",
            "Epoch 273/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6354 - accuracy: 0.3677 - val_loss: 1.6010 - val_accuracy: 0.4018\n",
            "Epoch 274/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6297 - accuracy: 0.3791 - val_loss: 1.5986 - val_accuracy: 0.4065\n",
            "Epoch 275/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6277 - accuracy: 0.3840 - val_loss: 1.5973 - val_accuracy: 0.4088\n",
            "Epoch 276/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.6227 - accuracy: 0.3826 - val_loss: 1.5998 - val_accuracy: 0.4053\n",
            "Epoch 277/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6448 - accuracy: 0.3736 - val_loss: 1.5970 - val_accuracy: 0.4007\n",
            "Epoch 278/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.6185 - accuracy: 0.3796 - val_loss: 1.5960 - val_accuracy: 0.4169\n",
            "Epoch 279/1000\n",
            "127/127 [==============================] - 9s 68ms/step - loss: 1.6216 - accuracy: 0.3890 - val_loss: 1.5948 - val_accuracy: 0.4099\n",
            "Epoch 280/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.6138 - accuracy: 0.3756 - val_loss: 1.5965 - val_accuracy: 0.4088\n",
            "Epoch 281/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6402 - accuracy: 0.3682 - val_loss: 1.5967 - val_accuracy: 0.3961\n",
            "Epoch 282/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6325 - accuracy: 0.3855 - val_loss: 1.5933 - val_accuracy: 0.4007\n",
            "Epoch 283/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.6221 - accuracy: 0.3811 - val_loss: 1.5943 - val_accuracy: 0.3938\n",
            "Epoch 284/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.6129 - accuracy: 0.3845 - val_loss: 1.5927 - val_accuracy: 0.4099\n",
            "Epoch 285/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.6154 - accuracy: 0.3771 - val_loss: 1.5928 - val_accuracy: 0.4053\n",
            "Epoch 286/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6108 - accuracy: 0.3900 - val_loss: 1.5913 - val_accuracy: 0.4180\n",
            "Epoch 287/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.6146 - accuracy: 0.3870 - val_loss: 1.5895 - val_accuracy: 0.4065\n",
            "Epoch 288/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6267 - accuracy: 0.3627 - val_loss: 1.5887 - val_accuracy: 0.3995\n",
            "Epoch 289/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6107 - accuracy: 0.3835 - val_loss: 1.5940 - val_accuracy: 0.4157\n",
            "Epoch 290/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6253 - accuracy: 0.3885 - val_loss: 1.5918 - val_accuracy: 0.4053\n",
            "Epoch 291/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6097 - accuracy: 0.3890 - val_loss: 1.5908 - val_accuracy: 0.3972\n",
            "Epoch 292/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6159 - accuracy: 0.3920 - val_loss: 1.5876 - val_accuracy: 0.4099\n",
            "Epoch 293/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6170 - accuracy: 0.3707 - val_loss: 1.5871 - val_accuracy: 0.3995\n",
            "Epoch 294/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.6095 - accuracy: 0.3925 - val_loss: 1.5854 - val_accuracy: 0.4111\n",
            "Epoch 295/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6137 - accuracy: 0.3831 - val_loss: 1.5859 - val_accuracy: 0.4122\n",
            "Epoch 296/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6070 - accuracy: 0.3766 - val_loss: 1.5857 - val_accuracy: 0.4122\n",
            "Epoch 297/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.6061 - accuracy: 0.3930 - val_loss: 1.5859 - val_accuracy: 0.4122\n",
            "Epoch 298/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.6108 - accuracy: 0.3826 - val_loss: 1.5786 - val_accuracy: 0.4111\n",
            "Epoch 299/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5932 - accuracy: 0.3930 - val_loss: 1.5809 - val_accuracy: 0.4088\n",
            "Epoch 300/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5963 - accuracy: 0.4014 - val_loss: 1.5805 - val_accuracy: 0.4180\n",
            "Epoch 301/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.6108 - accuracy: 0.3865 - val_loss: 1.5779 - val_accuracy: 0.4169\n",
            "Epoch 302/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6050 - accuracy: 0.3860 - val_loss: 1.5751 - val_accuracy: 0.4099\n",
            "Epoch 303/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5928 - accuracy: 0.4014 - val_loss: 1.5841 - val_accuracy: 0.4088\n",
            "Epoch 304/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.6102 - accuracy: 0.3840 - val_loss: 1.5726 - val_accuracy: 0.4157\n",
            "Epoch 305/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6107 - accuracy: 0.3910 - val_loss: 1.5744 - val_accuracy: 0.4157\n",
            "Epoch 306/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6024 - accuracy: 0.4019 - val_loss: 1.5734 - val_accuracy: 0.4099\n",
            "Epoch 307/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5974 - accuracy: 0.3875 - val_loss: 1.5763 - val_accuracy: 0.4088\n",
            "Epoch 308/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6009 - accuracy: 0.3831 - val_loss: 1.5694 - val_accuracy: 0.4215\n",
            "Epoch 309/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5909 - accuracy: 0.3940 - val_loss: 1.5783 - val_accuracy: 0.4134\n",
            "Epoch 310/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5951 - accuracy: 0.3979 - val_loss: 1.5703 - val_accuracy: 0.3984\n",
            "Epoch 311/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5938 - accuracy: 0.3994 - val_loss: 1.5779 - val_accuracy: 0.4134\n",
            "Epoch 312/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5979 - accuracy: 0.3845 - val_loss: 1.5705 - val_accuracy: 0.4157\n",
            "Epoch 313/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.6005 - accuracy: 0.3885 - val_loss: 1.5708 - val_accuracy: 0.4099\n",
            "Epoch 314/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5881 - accuracy: 0.3900 - val_loss: 1.5683 - val_accuracy: 0.4111\n",
            "Epoch 315/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.6018 - accuracy: 0.3974 - val_loss: 1.5654 - val_accuracy: 0.4099\n",
            "Epoch 316/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5911 - accuracy: 0.3944 - val_loss: 1.5660 - val_accuracy: 0.4099\n",
            "Epoch 317/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5965 - accuracy: 0.3940 - val_loss: 1.5674 - val_accuracy: 0.4122\n",
            "Epoch 318/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5821 - accuracy: 0.4083 - val_loss: 1.5645 - val_accuracy: 0.4134\n",
            "Epoch 319/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.5930 - accuracy: 0.3940 - val_loss: 1.5608 - val_accuracy: 0.4157\n",
            "Epoch 320/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5956 - accuracy: 0.4073 - val_loss: 1.5635 - val_accuracy: 0.4203\n",
            "Epoch 321/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5977 - accuracy: 0.3870 - val_loss: 1.5623 - val_accuracy: 0.4192\n",
            "Epoch 322/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5832 - accuracy: 0.3979 - val_loss: 1.5594 - val_accuracy: 0.4192\n",
            "Epoch 323/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5886 - accuracy: 0.3905 - val_loss: 1.5642 - val_accuracy: 0.4145\n",
            "Epoch 324/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5789 - accuracy: 0.3954 - val_loss: 1.5594 - val_accuracy: 0.4053\n",
            "Epoch 325/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5761 - accuracy: 0.4153 - val_loss: 1.5591 - val_accuracy: 0.4192\n",
            "Epoch 326/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5907 - accuracy: 0.3890 - val_loss: 1.5631 - val_accuracy: 0.4180\n",
            "Epoch 327/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5871 - accuracy: 0.3920 - val_loss: 1.5585 - val_accuracy: 0.4169\n",
            "Epoch 328/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5744 - accuracy: 0.4083 - val_loss: 1.5590 - val_accuracy: 0.4111\n",
            "Epoch 329/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5756 - accuracy: 0.3994 - val_loss: 1.5546 - val_accuracy: 0.4192\n",
            "Epoch 330/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5779 - accuracy: 0.4068 - val_loss: 1.5545 - val_accuracy: 0.4122\n",
            "Epoch 331/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5874 - accuracy: 0.3989 - val_loss: 1.5561 - val_accuracy: 0.4180\n",
            "Epoch 332/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5690 - accuracy: 0.3845 - val_loss: 1.5610 - val_accuracy: 0.4238\n",
            "Epoch 333/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5739 - accuracy: 0.4093 - val_loss: 1.5539 - val_accuracy: 0.4203\n",
            "Epoch 334/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5708 - accuracy: 0.4108 - val_loss: 1.5530 - val_accuracy: 0.4226\n",
            "Epoch 335/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.5745 - accuracy: 0.3989 - val_loss: 1.5524 - val_accuracy: 0.4203\n",
            "Epoch 336/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5768 - accuracy: 0.3999 - val_loss: 1.5481 - val_accuracy: 0.4180\n",
            "Epoch 337/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5837 - accuracy: 0.3969 - val_loss: 1.5536 - val_accuracy: 0.4249\n",
            "Epoch 338/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.5636 - accuracy: 0.3954 - val_loss: 1.5531 - val_accuracy: 0.4203\n",
            "Epoch 339/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5748 - accuracy: 0.3964 - val_loss: 1.5506 - val_accuracy: 0.4226\n",
            "Epoch 340/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5806 - accuracy: 0.4128 - val_loss: 1.5475 - val_accuracy: 0.4203\n",
            "Epoch 341/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5759 - accuracy: 0.3989 - val_loss: 1.5505 - val_accuracy: 0.4273\n",
            "Epoch 342/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5722 - accuracy: 0.4073 - val_loss: 1.5467 - val_accuracy: 0.4215\n",
            "Epoch 343/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5742 - accuracy: 0.4068 - val_loss: 1.5500 - val_accuracy: 0.4273\n",
            "Epoch 344/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.5673 - accuracy: 0.4103 - val_loss: 1.5457 - val_accuracy: 0.4273\n",
            "Epoch 345/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.5668 - accuracy: 0.4143 - val_loss: 1.5453 - val_accuracy: 0.4203\n",
            "Epoch 346/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5603 - accuracy: 0.4083 - val_loss: 1.5474 - val_accuracy: 0.4215\n",
            "Epoch 347/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5681 - accuracy: 0.4073 - val_loss: 1.5452 - val_accuracy: 0.4192\n",
            "Epoch 348/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5720 - accuracy: 0.4014 - val_loss: 1.5436 - val_accuracy: 0.4192\n",
            "Epoch 349/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5672 - accuracy: 0.4029 - val_loss: 1.5404 - val_accuracy: 0.4157\n",
            "Epoch 350/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5679 - accuracy: 0.4034 - val_loss: 1.5424 - val_accuracy: 0.4122\n",
            "Epoch 351/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.5581 - accuracy: 0.4078 - val_loss: 1.5407 - val_accuracy: 0.4238\n",
            "Epoch 352/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.5595 - accuracy: 0.4138 - val_loss: 1.5375 - val_accuracy: 0.4238\n",
            "Epoch 353/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.5509 - accuracy: 0.4148 - val_loss: 1.5450 - val_accuracy: 0.4273\n",
            "Epoch 354/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5536 - accuracy: 0.4153 - val_loss: 1.5447 - val_accuracy: 0.4296\n",
            "Epoch 355/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5618 - accuracy: 0.4133 - val_loss: 1.5378 - val_accuracy: 0.4330\n",
            "Epoch 356/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.5651 - accuracy: 0.4054 - val_loss: 1.5441 - val_accuracy: 0.4203\n",
            "Epoch 357/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5531 - accuracy: 0.4098 - val_loss: 1.5581 - val_accuracy: 0.4111\n",
            "Epoch 358/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.5559 - accuracy: 0.4004 - val_loss: 1.5442 - val_accuracy: 0.4169\n",
            "Epoch 359/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.5563 - accuracy: 0.4058 - val_loss: 1.5349 - val_accuracy: 0.4284\n",
            "Epoch 360/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5609 - accuracy: 0.4068 - val_loss: 1.5376 - val_accuracy: 0.4319\n",
            "Epoch 361/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5498 - accuracy: 0.4108 - val_loss: 1.5356 - val_accuracy: 0.4273\n",
            "Epoch 362/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5494 - accuracy: 0.4242 - val_loss: 1.5357 - val_accuracy: 0.4192\n",
            "Epoch 363/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5582 - accuracy: 0.4068 - val_loss: 1.5319 - val_accuracy: 0.4307\n",
            "Epoch 364/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5543 - accuracy: 0.4177 - val_loss: 1.5385 - val_accuracy: 0.4249\n",
            "Epoch 365/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5534 - accuracy: 0.4073 - val_loss: 1.5368 - val_accuracy: 0.4273\n",
            "Epoch 366/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5519 - accuracy: 0.4073 - val_loss: 1.5333 - val_accuracy: 0.4296\n",
            "Epoch 367/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5368 - accuracy: 0.4163 - val_loss: 1.5380 - val_accuracy: 0.4307\n",
            "Epoch 368/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5522 - accuracy: 0.4222 - val_loss: 1.5362 - val_accuracy: 0.4203\n",
            "Epoch 369/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5377 - accuracy: 0.4222 - val_loss: 1.5318 - val_accuracy: 0.4249\n",
            "Epoch 370/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5351 - accuracy: 0.4153 - val_loss: 1.5375 - val_accuracy: 0.4192\n",
            "Epoch 371/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5490 - accuracy: 0.4192 - val_loss: 1.5304 - val_accuracy: 0.4261\n",
            "Epoch 372/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.5450 - accuracy: 0.4138 - val_loss: 1.5419 - val_accuracy: 0.4238\n",
            "Epoch 373/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.5506 - accuracy: 0.4118 - val_loss: 1.5267 - val_accuracy: 0.4261\n",
            "Epoch 374/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.5372 - accuracy: 0.4242 - val_loss: 1.5236 - val_accuracy: 0.4296\n",
            "Epoch 375/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.5391 - accuracy: 0.4148 - val_loss: 1.5293 - val_accuracy: 0.4319\n",
            "Epoch 376/1000\n",
            "127/127 [==============================] - 9s 69ms/step - loss: 1.5435 - accuracy: 0.4113 - val_loss: 1.5237 - val_accuracy: 0.4307\n",
            "Epoch 377/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.5455 - accuracy: 0.4068 - val_loss: 1.5229 - val_accuracy: 0.4226\n",
            "Epoch 378/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5392 - accuracy: 0.4222 - val_loss: 1.5293 - val_accuracy: 0.4342\n",
            "Epoch 379/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5343 - accuracy: 0.4078 - val_loss: 1.5308 - val_accuracy: 0.4180\n",
            "Epoch 380/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5517 - accuracy: 0.4108 - val_loss: 1.5327 - val_accuracy: 0.4180\n",
            "Epoch 381/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5376 - accuracy: 0.4167 - val_loss: 1.5300 - val_accuracy: 0.4330\n",
            "Epoch 382/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5307 - accuracy: 0.4272 - val_loss: 1.5297 - val_accuracy: 0.4261\n",
            "Epoch 383/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5429 - accuracy: 0.4058 - val_loss: 1.5222 - val_accuracy: 0.4353\n",
            "Epoch 384/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5258 - accuracy: 0.4237 - val_loss: 1.5286 - val_accuracy: 0.4273\n",
            "Epoch 385/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5422 - accuracy: 0.4034 - val_loss: 1.5251 - val_accuracy: 0.4400\n",
            "Epoch 386/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5356 - accuracy: 0.4182 - val_loss: 1.5276 - val_accuracy: 0.4249\n",
            "Epoch 387/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5393 - accuracy: 0.4113 - val_loss: 1.5223 - val_accuracy: 0.4215\n",
            "Epoch 388/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5373 - accuracy: 0.4177 - val_loss: 1.5192 - val_accuracy: 0.4330\n",
            "Epoch 389/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5208 - accuracy: 0.4257 - val_loss: 1.5165 - val_accuracy: 0.4226\n",
            "Epoch 390/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5330 - accuracy: 0.4262 - val_loss: 1.5196 - val_accuracy: 0.4319\n",
            "Epoch 391/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5264 - accuracy: 0.4167 - val_loss: 1.5180 - val_accuracy: 0.4249\n",
            "Epoch 392/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5283 - accuracy: 0.4103 - val_loss: 1.5170 - val_accuracy: 0.4261\n",
            "Epoch 393/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5303 - accuracy: 0.4217 - val_loss: 1.5144 - val_accuracy: 0.4215\n",
            "Epoch 394/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5267 - accuracy: 0.4192 - val_loss: 1.5378 - val_accuracy: 0.4376\n",
            "Epoch 395/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5435 - accuracy: 0.4187 - val_loss: 1.5149 - val_accuracy: 0.4330\n",
            "Epoch 396/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5233 - accuracy: 0.4167 - val_loss: 1.5114 - val_accuracy: 0.4284\n",
            "Epoch 397/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5245 - accuracy: 0.4257 - val_loss: 1.5186 - val_accuracy: 0.4238\n",
            "Epoch 398/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5197 - accuracy: 0.4177 - val_loss: 1.5213 - val_accuracy: 0.4353\n",
            "Epoch 399/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5291 - accuracy: 0.4207 - val_loss: 1.5169 - val_accuracy: 0.4261\n",
            "Epoch 400/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.5231 - accuracy: 0.4291 - val_loss: 1.5140 - val_accuracy: 0.4319\n",
            "Epoch 401/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5196 - accuracy: 0.4192 - val_loss: 1.5124 - val_accuracy: 0.4215\n",
            "Epoch 402/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5177 - accuracy: 0.4232 - val_loss: 1.5146 - val_accuracy: 0.4342\n",
            "Epoch 403/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5179 - accuracy: 0.4281 - val_loss: 1.5138 - val_accuracy: 0.4457\n",
            "Epoch 404/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5269 - accuracy: 0.4153 - val_loss: 1.5059 - val_accuracy: 0.4307\n",
            "Epoch 405/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5118 - accuracy: 0.4267 - val_loss: 1.5115 - val_accuracy: 0.4353\n",
            "Epoch 406/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5119 - accuracy: 0.4281 - val_loss: 1.5057 - val_accuracy: 0.4330\n",
            "Epoch 407/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5180 - accuracy: 0.4177 - val_loss: 1.5089 - val_accuracy: 0.4307\n",
            "Epoch 408/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5375 - accuracy: 0.4123 - val_loss: 1.5134 - val_accuracy: 0.4376\n",
            "Epoch 409/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.5097 - accuracy: 0.4351 - val_loss: 1.5091 - val_accuracy: 0.4307\n",
            "Epoch 410/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.5097 - accuracy: 0.4138 - val_loss: 1.5104 - val_accuracy: 0.4284\n",
            "Epoch 411/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.4988 - accuracy: 0.4400 - val_loss: 1.5067 - val_accuracy: 0.4238\n",
            "Epoch 412/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5114 - accuracy: 0.4371 - val_loss: 1.5055 - val_accuracy: 0.4284\n",
            "Epoch 413/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5083 - accuracy: 0.4237 - val_loss: 1.5095 - val_accuracy: 0.4261\n",
            "Epoch 414/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5099 - accuracy: 0.4222 - val_loss: 1.5102 - val_accuracy: 0.4307\n",
            "Epoch 415/1000\n",
            "127/127 [==============================] - 6s 48ms/step - loss: 1.5068 - accuracy: 0.4267 - val_loss: 1.5089 - val_accuracy: 0.4365\n",
            "Epoch 416/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.5147 - accuracy: 0.4197 - val_loss: 1.5111 - val_accuracy: 0.4261\n",
            "Epoch 417/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.5045 - accuracy: 0.4262 - val_loss: 1.5013 - val_accuracy: 0.4388\n",
            "Epoch 418/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5037 - accuracy: 0.4177 - val_loss: 1.5008 - val_accuracy: 0.4238\n",
            "Epoch 419/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.5071 - accuracy: 0.4182 - val_loss: 1.4995 - val_accuracy: 0.4365\n",
            "Epoch 420/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5047 - accuracy: 0.4252 - val_loss: 1.4995 - val_accuracy: 0.4342\n",
            "Epoch 421/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4969 - accuracy: 0.4311 - val_loss: 1.4992 - val_accuracy: 0.4411\n",
            "Epoch 422/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.5149 - accuracy: 0.4272 - val_loss: 1.4983 - val_accuracy: 0.4365\n",
            "Epoch 423/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.5020 - accuracy: 0.4232 - val_loss: 1.5025 - val_accuracy: 0.4365\n",
            "Epoch 424/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.5014 - accuracy: 0.4272 - val_loss: 1.4975 - val_accuracy: 0.4330\n",
            "Epoch 425/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.5062 - accuracy: 0.4326 - val_loss: 1.4958 - val_accuracy: 0.4307\n",
            "Epoch 426/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4920 - accuracy: 0.4262 - val_loss: 1.4934 - val_accuracy: 0.4342\n",
            "Epoch 427/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4996 - accuracy: 0.4242 - val_loss: 1.4950 - val_accuracy: 0.4273\n",
            "Epoch 428/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.5053 - accuracy: 0.4366 - val_loss: 1.5000 - val_accuracy: 0.4400\n",
            "Epoch 429/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4823 - accuracy: 0.4376 - val_loss: 1.4969 - val_accuracy: 0.4273\n",
            "Epoch 430/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4939 - accuracy: 0.4252 - val_loss: 1.4936 - val_accuracy: 0.4353\n",
            "Epoch 431/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4993 - accuracy: 0.4187 - val_loss: 1.4890 - val_accuracy: 0.4273\n",
            "Epoch 432/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.5120 - accuracy: 0.4153 - val_loss: 1.4967 - val_accuracy: 0.4411\n",
            "Epoch 433/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4955 - accuracy: 0.4366 - val_loss: 1.4866 - val_accuracy: 0.4319\n",
            "Epoch 434/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.5015 - accuracy: 0.4321 - val_loss: 1.4895 - val_accuracy: 0.4376\n",
            "Epoch 435/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4952 - accuracy: 0.4326 - val_loss: 1.4910 - val_accuracy: 0.4376\n",
            "Epoch 436/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4839 - accuracy: 0.4430 - val_loss: 1.4883 - val_accuracy: 0.4400\n",
            "Epoch 437/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4783 - accuracy: 0.4519 - val_loss: 1.4877 - val_accuracy: 0.4376\n",
            "Epoch 438/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4810 - accuracy: 0.4346 - val_loss: 1.4944 - val_accuracy: 0.4330\n",
            "Epoch 439/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4927 - accuracy: 0.4311 - val_loss: 1.4876 - val_accuracy: 0.4423\n",
            "Epoch 440/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4820 - accuracy: 0.4371 - val_loss: 1.4890 - val_accuracy: 0.4400\n",
            "Epoch 441/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4817 - accuracy: 0.4336 - val_loss: 1.4875 - val_accuracy: 0.4388\n",
            "Epoch 442/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4864 - accuracy: 0.4410 - val_loss: 1.4934 - val_accuracy: 0.4388\n",
            "Epoch 443/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4944 - accuracy: 0.4187 - val_loss: 1.4782 - val_accuracy: 0.4330\n",
            "Epoch 444/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4764 - accuracy: 0.4405 - val_loss: 1.4817 - val_accuracy: 0.4296\n",
            "Epoch 445/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4913 - accuracy: 0.4286 - val_loss: 1.4782 - val_accuracy: 0.4400\n",
            "Epoch 446/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.4864 - accuracy: 0.4460 - val_loss: 1.4840 - val_accuracy: 0.4376\n",
            "Epoch 447/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4888 - accuracy: 0.4281 - val_loss: 1.4808 - val_accuracy: 0.4307\n",
            "Epoch 448/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4778 - accuracy: 0.4336 - val_loss: 1.4957 - val_accuracy: 0.4353\n",
            "Epoch 449/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4719 - accuracy: 0.4381 - val_loss: 1.4969 - val_accuracy: 0.4503\n",
            "Epoch 450/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4760 - accuracy: 0.4356 - val_loss: 1.4753 - val_accuracy: 0.4296\n",
            "Epoch 451/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4739 - accuracy: 0.4346 - val_loss: 1.4776 - val_accuracy: 0.4400\n",
            "Epoch 452/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4680 - accuracy: 0.4390 - val_loss: 1.4775 - val_accuracy: 0.4330\n",
            "Epoch 453/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.4787 - accuracy: 0.4346 - val_loss: 1.4860 - val_accuracy: 0.4538\n",
            "Epoch 454/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4736 - accuracy: 0.4425 - val_loss: 1.4833 - val_accuracy: 0.4388\n",
            "Epoch 455/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4614 - accuracy: 0.4410 - val_loss: 1.4863 - val_accuracy: 0.4480\n",
            "Epoch 456/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4722 - accuracy: 0.4376 - val_loss: 1.4734 - val_accuracy: 0.4434\n",
            "Epoch 457/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4633 - accuracy: 0.4445 - val_loss: 1.4689 - val_accuracy: 0.4434\n",
            "Epoch 458/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4606 - accuracy: 0.4390 - val_loss: 1.4788 - val_accuracy: 0.4411\n",
            "Epoch 459/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4762 - accuracy: 0.4296 - val_loss: 1.4689 - val_accuracy: 0.4400\n",
            "Epoch 460/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4616 - accuracy: 0.4371 - val_loss: 1.4684 - val_accuracy: 0.4446\n",
            "Epoch 461/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4684 - accuracy: 0.4410 - val_loss: 1.4858 - val_accuracy: 0.4607\n",
            "Epoch 462/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4730 - accuracy: 0.4435 - val_loss: 1.4655 - val_accuracy: 0.4527\n",
            "Epoch 463/1000\n",
            "127/127 [==============================] - 8s 67ms/step - loss: 1.4823 - accuracy: 0.4346 - val_loss: 1.4661 - val_accuracy: 0.4527\n",
            "Epoch 464/1000\n",
            "127/127 [==============================] - 9s 72ms/step - loss: 1.4816 - accuracy: 0.4306 - val_loss: 1.4653 - val_accuracy: 0.4457\n",
            "Epoch 465/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4435 - accuracy: 0.4559 - val_loss: 1.4700 - val_accuracy: 0.4480\n",
            "Epoch 466/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4659 - accuracy: 0.4366 - val_loss: 1.4692 - val_accuracy: 0.4446\n",
            "Epoch 467/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4595 - accuracy: 0.4405 - val_loss: 1.4753 - val_accuracy: 0.4423\n",
            "Epoch 468/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4845 - accuracy: 0.4252 - val_loss: 1.4673 - val_accuracy: 0.4423\n",
            "Epoch 469/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4606 - accuracy: 0.4435 - val_loss: 1.4681 - val_accuracy: 0.4550\n",
            "Epoch 470/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4626 - accuracy: 0.4445 - val_loss: 1.4616 - val_accuracy: 0.4480\n",
            "Epoch 471/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4561 - accuracy: 0.4405 - val_loss: 1.4660 - val_accuracy: 0.4423\n",
            "Epoch 472/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4517 - accuracy: 0.4425 - val_loss: 1.4602 - val_accuracy: 0.4376\n",
            "Epoch 473/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4648 - accuracy: 0.4311 - val_loss: 1.4630 - val_accuracy: 0.4492\n",
            "Epoch 474/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4589 - accuracy: 0.4564 - val_loss: 1.4630 - val_accuracy: 0.4538\n",
            "Epoch 475/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4636 - accuracy: 0.4470 - val_loss: 1.4630 - val_accuracy: 0.4527\n",
            "Epoch 476/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4456 - accuracy: 0.4440 - val_loss: 1.4582 - val_accuracy: 0.4400\n",
            "Epoch 477/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4618 - accuracy: 0.4440 - val_loss: 1.4604 - val_accuracy: 0.4515\n",
            "Epoch 478/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.4471 - accuracy: 0.4410 - val_loss: 1.4553 - val_accuracy: 0.4538\n",
            "Epoch 479/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.4538 - accuracy: 0.4465 - val_loss: 1.4595 - val_accuracy: 0.4446\n",
            "Epoch 480/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4454 - accuracy: 0.4524 - val_loss: 1.4600 - val_accuracy: 0.4400\n",
            "Epoch 481/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4590 - accuracy: 0.4395 - val_loss: 1.4565 - val_accuracy: 0.4469\n",
            "Epoch 482/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4627 - accuracy: 0.4356 - val_loss: 1.4533 - val_accuracy: 0.4503\n",
            "Epoch 483/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4424 - accuracy: 0.4410 - val_loss: 1.4511 - val_accuracy: 0.4550\n",
            "Epoch 484/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4482 - accuracy: 0.4435 - val_loss: 1.4533 - val_accuracy: 0.4446\n",
            "Epoch 485/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4561 - accuracy: 0.4331 - val_loss: 1.4608 - val_accuracy: 0.4538\n",
            "Epoch 486/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4565 - accuracy: 0.4455 - val_loss: 1.4555 - val_accuracy: 0.4503\n",
            "Epoch 487/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4411 - accuracy: 0.4480 - val_loss: 1.4519 - val_accuracy: 0.4469\n",
            "Epoch 488/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4600 - accuracy: 0.4450 - val_loss: 1.4482 - val_accuracy: 0.4469\n",
            "Epoch 489/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4463 - accuracy: 0.4465 - val_loss: 1.4564 - val_accuracy: 0.4503\n",
            "Epoch 490/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4420 - accuracy: 0.4519 - val_loss: 1.4561 - val_accuracy: 0.4607\n",
            "Epoch 491/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4434 - accuracy: 0.4386 - val_loss: 1.4479 - val_accuracy: 0.4503\n",
            "Epoch 492/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.4402 - accuracy: 0.4371 - val_loss: 1.4604 - val_accuracy: 0.4469\n",
            "Epoch 493/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.4335 - accuracy: 0.4455 - val_loss: 1.4551 - val_accuracy: 0.4457\n",
            "Epoch 494/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.4377 - accuracy: 0.4495 - val_loss: 1.4547 - val_accuracy: 0.4457\n",
            "Epoch 495/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4433 - accuracy: 0.4440 - val_loss: 1.4461 - val_accuracy: 0.4596\n",
            "Epoch 496/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4454 - accuracy: 0.4554 - val_loss: 1.4465 - val_accuracy: 0.4550\n",
            "Epoch 497/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4330 - accuracy: 0.4500 - val_loss: 1.4490 - val_accuracy: 0.4457\n",
            "Epoch 498/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4368 - accuracy: 0.4405 - val_loss: 1.4534 - val_accuracy: 0.4550\n",
            "Epoch 499/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4420 - accuracy: 0.4460 - val_loss: 1.4465 - val_accuracy: 0.4561\n",
            "Epoch 500/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4388 - accuracy: 0.4435 - val_loss: 1.4517 - val_accuracy: 0.4400\n",
            "Epoch 501/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4444 - accuracy: 0.4460 - val_loss: 1.4471 - val_accuracy: 0.4515\n",
            "Epoch 502/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.4278 - accuracy: 0.4519 - val_loss: 1.4456 - val_accuracy: 0.4457\n",
            "Epoch 503/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4184 - accuracy: 0.4495 - val_loss: 1.4492 - val_accuracy: 0.4515\n",
            "Epoch 504/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.4248 - accuracy: 0.4559 - val_loss: 1.4457 - val_accuracy: 0.4561\n",
            "Epoch 505/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4236 - accuracy: 0.4495 - val_loss: 1.4441 - val_accuracy: 0.4492\n",
            "Epoch 506/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.4360 - accuracy: 0.4524 - val_loss: 1.4462 - val_accuracy: 0.4400\n",
            "Epoch 507/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4379 - accuracy: 0.4519 - val_loss: 1.4423 - val_accuracy: 0.4492\n",
            "Epoch 508/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4207 - accuracy: 0.4475 - val_loss: 1.4506 - val_accuracy: 0.4492\n",
            "Epoch 509/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4326 - accuracy: 0.4485 - val_loss: 1.4423 - val_accuracy: 0.4527\n",
            "Epoch 510/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4264 - accuracy: 0.4544 - val_loss: 1.4426 - val_accuracy: 0.4503\n",
            "Epoch 511/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4417 - accuracy: 0.4470 - val_loss: 1.4470 - val_accuracy: 0.4607\n",
            "Epoch 512/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4265 - accuracy: 0.4549 - val_loss: 1.4413 - val_accuracy: 0.4515\n",
            "Epoch 513/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4263 - accuracy: 0.4579 - val_loss: 1.4437 - val_accuracy: 0.4561\n",
            "Epoch 514/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4256 - accuracy: 0.4569 - val_loss: 1.4407 - val_accuracy: 0.4515\n",
            "Epoch 515/1000\n",
            "127/127 [==============================] - 9s 71ms/step - loss: 1.4287 - accuracy: 0.4579 - val_loss: 1.4404 - val_accuracy: 0.4480\n",
            "Epoch 516/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.4233 - accuracy: 0.4435 - val_loss: 1.4418 - val_accuracy: 0.4561\n",
            "Epoch 517/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4208 - accuracy: 0.4564 - val_loss: 1.4364 - val_accuracy: 0.4515\n",
            "Epoch 518/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.4246 - accuracy: 0.4465 - val_loss: 1.4529 - val_accuracy: 0.4388\n",
            "Epoch 519/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.4287 - accuracy: 0.4584 - val_loss: 1.4380 - val_accuracy: 0.4527\n",
            "Epoch 520/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.4238 - accuracy: 0.4485 - val_loss: 1.4451 - val_accuracy: 0.4492\n",
            "Epoch 521/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4187 - accuracy: 0.4559 - val_loss: 1.4432 - val_accuracy: 0.4446\n",
            "Epoch 522/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4052 - accuracy: 0.4618 - val_loss: 1.4347 - val_accuracy: 0.4457\n",
            "Epoch 523/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4251 - accuracy: 0.4480 - val_loss: 1.4374 - val_accuracy: 0.4457\n",
            "Epoch 524/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.4176 - accuracy: 0.4574 - val_loss: 1.4391 - val_accuracy: 0.4434\n",
            "Epoch 525/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.4153 - accuracy: 0.4544 - val_loss: 1.4412 - val_accuracy: 0.4527\n",
            "Epoch 526/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4200 - accuracy: 0.4564 - val_loss: 1.4386 - val_accuracy: 0.4584\n",
            "Epoch 527/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4209 - accuracy: 0.4564 - val_loss: 1.4350 - val_accuracy: 0.4492\n",
            "Epoch 528/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4180 - accuracy: 0.4470 - val_loss: 1.4377 - val_accuracy: 0.4538\n",
            "Epoch 529/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4158 - accuracy: 0.4514 - val_loss: 1.4326 - val_accuracy: 0.4515\n",
            "Epoch 530/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4163 - accuracy: 0.4485 - val_loss: 1.4325 - val_accuracy: 0.4480\n",
            "Epoch 531/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4173 - accuracy: 0.4584 - val_loss: 1.4315 - val_accuracy: 0.4423\n",
            "Epoch 532/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.4150 - accuracy: 0.4633 - val_loss: 1.4289 - val_accuracy: 0.4503\n",
            "Epoch 533/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4254 - accuracy: 0.4376 - val_loss: 1.4340 - val_accuracy: 0.4538\n",
            "Epoch 534/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.4174 - accuracy: 0.4450 - val_loss: 1.4352 - val_accuracy: 0.4538\n",
            "Epoch 535/1000\n",
            "127/127 [==============================] - 8s 67ms/step - loss: 1.4136 - accuracy: 0.4504 - val_loss: 1.4403 - val_accuracy: 0.4596\n",
            "Epoch 536/1000\n",
            "127/127 [==============================] - 10s 76ms/step - loss: 1.4112 - accuracy: 0.4613 - val_loss: 1.4315 - val_accuracy: 0.4503\n",
            "Epoch 537/1000\n",
            "127/127 [==============================] - 10s 75ms/step - loss: 1.4029 - accuracy: 0.4613 - val_loss: 1.4326 - val_accuracy: 0.4492\n",
            "Epoch 538/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.3976 - accuracy: 0.4618 - val_loss: 1.4293 - val_accuracy: 0.4515\n",
            "Epoch 539/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4187 - accuracy: 0.4519 - val_loss: 1.4292 - val_accuracy: 0.4503\n",
            "Epoch 540/1000\n",
            "127/127 [==============================] - 9s 72ms/step - loss: 1.4111 - accuracy: 0.4514 - val_loss: 1.4276 - val_accuracy: 0.4527\n",
            "Epoch 541/1000\n",
            "127/127 [==============================] - 9s 68ms/step - loss: 1.4149 - accuracy: 0.4549 - val_loss: 1.4303 - val_accuracy: 0.4561\n",
            "Epoch 542/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4015 - accuracy: 0.4579 - val_loss: 1.4318 - val_accuracy: 0.4457\n",
            "Epoch 543/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.4065 - accuracy: 0.4623 - val_loss: 1.4256 - val_accuracy: 0.4607\n",
            "Epoch 544/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4108 - accuracy: 0.4673 - val_loss: 1.4266 - val_accuracy: 0.4550\n",
            "Epoch 545/1000\n",
            "127/127 [==============================] - 9s 68ms/step - loss: 1.4124 - accuracy: 0.4584 - val_loss: 1.4294 - val_accuracy: 0.4561\n",
            "Epoch 546/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4012 - accuracy: 0.4613 - val_loss: 1.4248 - val_accuracy: 0.4538\n",
            "Epoch 547/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.4076 - accuracy: 0.4653 - val_loss: 1.4383 - val_accuracy: 0.4503\n",
            "Epoch 548/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.4083 - accuracy: 0.4504 - val_loss: 1.4259 - val_accuracy: 0.4527\n",
            "Epoch 549/1000\n",
            "127/127 [==============================] - 9s 68ms/step - loss: 1.3996 - accuracy: 0.4599 - val_loss: 1.4424 - val_accuracy: 0.4561\n",
            "Epoch 550/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.4019 - accuracy: 0.4529 - val_loss: 1.4279 - val_accuracy: 0.4434\n",
            "Epoch 551/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4024 - accuracy: 0.4613 - val_loss: 1.4301 - val_accuracy: 0.4492\n",
            "Epoch 552/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3963 - accuracy: 0.4549 - val_loss: 1.4257 - val_accuracy: 0.4550\n",
            "Epoch 553/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3985 - accuracy: 0.4673 - val_loss: 1.4309 - val_accuracy: 0.4538\n",
            "Epoch 554/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.4055 - accuracy: 0.4504 - val_loss: 1.4275 - val_accuracy: 0.4573\n",
            "Epoch 555/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.3959 - accuracy: 0.4504 - val_loss: 1.4241 - val_accuracy: 0.4596\n",
            "Epoch 556/1000\n",
            "127/127 [==============================] - 6s 49ms/step - loss: 1.4012 - accuracy: 0.4579 - val_loss: 1.4558 - val_accuracy: 0.4561\n",
            "Epoch 557/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.4027 - accuracy: 0.4638 - val_loss: 1.4242 - val_accuracy: 0.4607\n",
            "Epoch 558/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3884 - accuracy: 0.4693 - val_loss: 1.4296 - val_accuracy: 0.4550\n",
            "Epoch 559/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4040 - accuracy: 0.4549 - val_loss: 1.4190 - val_accuracy: 0.4527\n",
            "Epoch 560/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4002 - accuracy: 0.4569 - val_loss: 1.4214 - val_accuracy: 0.4561\n",
            "Epoch 561/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3993 - accuracy: 0.4584 - val_loss: 1.4407 - val_accuracy: 0.4527\n",
            "Epoch 562/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.4016 - accuracy: 0.4594 - val_loss: 1.4181 - val_accuracy: 0.4503\n",
            "Epoch 563/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.4065 - accuracy: 0.4574 - val_loss: 1.4219 - val_accuracy: 0.4619\n",
            "Epoch 564/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3940 - accuracy: 0.4544 - val_loss: 1.4340 - val_accuracy: 0.4550\n",
            "Epoch 565/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4060 - accuracy: 0.4609 - val_loss: 1.4188 - val_accuracy: 0.4480\n",
            "Epoch 566/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.4098 - accuracy: 0.4544 - val_loss: 1.4202 - val_accuracy: 0.4480\n",
            "Epoch 567/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3887 - accuracy: 0.4683 - val_loss: 1.4252 - val_accuracy: 0.4492\n",
            "Epoch 568/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.4024 - accuracy: 0.4579 - val_loss: 1.4180 - val_accuracy: 0.4538\n",
            "Epoch 569/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.3897 - accuracy: 0.4579 - val_loss: 1.4190 - val_accuracy: 0.4538\n",
            "Epoch 570/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3968 - accuracy: 0.4574 - val_loss: 1.4236 - val_accuracy: 0.4503\n",
            "Epoch 571/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3947 - accuracy: 0.4653 - val_loss: 1.4131 - val_accuracy: 0.4573\n",
            "Epoch 572/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3956 - accuracy: 0.4623 - val_loss: 1.4434 - val_accuracy: 0.4550\n",
            "Epoch 573/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3918 - accuracy: 0.4678 - val_loss: 1.4219 - val_accuracy: 0.4630\n",
            "Epoch 574/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3880 - accuracy: 0.4688 - val_loss: 1.4233 - val_accuracy: 0.4480\n",
            "Epoch 575/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3981 - accuracy: 0.4465 - val_loss: 1.4117 - val_accuracy: 0.4596\n",
            "Epoch 576/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3890 - accuracy: 0.4633 - val_loss: 1.4228 - val_accuracy: 0.4573\n",
            "Epoch 577/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3881 - accuracy: 0.4703 - val_loss: 1.4189 - val_accuracy: 0.4630\n",
            "Epoch 578/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3934 - accuracy: 0.4623 - val_loss: 1.4252 - val_accuracy: 0.4527\n",
            "Epoch 579/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3793 - accuracy: 0.4673 - val_loss: 1.4190 - val_accuracy: 0.4642\n",
            "Epoch 580/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.4109 - accuracy: 0.4534 - val_loss: 1.4330 - val_accuracy: 0.4561\n",
            "Epoch 581/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3783 - accuracy: 0.4727 - val_loss: 1.4211 - val_accuracy: 0.4596\n",
            "Epoch 582/1000\n",
            "127/127 [==============================] - 7s 51ms/step - loss: 1.3924 - accuracy: 0.4604 - val_loss: 1.4100 - val_accuracy: 0.4630\n",
            "Epoch 583/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3942 - accuracy: 0.4693 - val_loss: 1.4223 - val_accuracy: 0.4654\n",
            "Epoch 584/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3914 - accuracy: 0.4688 - val_loss: 1.4143 - val_accuracy: 0.4677\n",
            "Epoch 585/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3814 - accuracy: 0.4688 - val_loss: 1.4165 - val_accuracy: 0.4527\n",
            "Epoch 586/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3792 - accuracy: 0.4623 - val_loss: 1.4175 - val_accuracy: 0.4607\n",
            "Epoch 587/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3870 - accuracy: 0.4663 - val_loss: 1.4150 - val_accuracy: 0.4573\n",
            "Epoch 588/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3776 - accuracy: 0.4574 - val_loss: 1.4104 - val_accuracy: 0.4654\n",
            "Epoch 589/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.3845 - accuracy: 0.4653 - val_loss: 1.4151 - val_accuracy: 0.4538\n",
            "Epoch 590/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3802 - accuracy: 0.4663 - val_loss: 1.4077 - val_accuracy: 0.4619\n",
            "Epoch 591/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3859 - accuracy: 0.4737 - val_loss: 1.4149 - val_accuracy: 0.4561\n",
            "Epoch 592/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3743 - accuracy: 0.4708 - val_loss: 1.4084 - val_accuracy: 0.4665\n",
            "Epoch 593/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3796 - accuracy: 0.4752 - val_loss: 1.4161 - val_accuracy: 0.4596\n",
            "Epoch 594/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3712 - accuracy: 0.4822 - val_loss: 1.4234 - val_accuracy: 0.4573\n",
            "Epoch 595/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3771 - accuracy: 0.4718 - val_loss: 1.4195 - val_accuracy: 0.4550\n",
            "Epoch 596/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3900 - accuracy: 0.4519 - val_loss: 1.4177 - val_accuracy: 0.4654\n",
            "Epoch 597/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3713 - accuracy: 0.4722 - val_loss: 1.4103 - val_accuracy: 0.4584\n",
            "Epoch 598/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3883 - accuracy: 0.4594 - val_loss: 1.4204 - val_accuracy: 0.4538\n",
            "Epoch 599/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3724 - accuracy: 0.4643 - val_loss: 1.4164 - val_accuracy: 0.4642\n",
            "Epoch 600/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3692 - accuracy: 0.4713 - val_loss: 1.4165 - val_accuracy: 0.4607\n",
            "Epoch 601/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.3786 - accuracy: 0.4599 - val_loss: 1.4140 - val_accuracy: 0.4711\n",
            "Epoch 602/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3839 - accuracy: 0.4638 - val_loss: 1.4101 - val_accuracy: 0.4665\n",
            "Epoch 603/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3814 - accuracy: 0.4673 - val_loss: 1.4057 - val_accuracy: 0.4642\n",
            "Epoch 604/1000\n",
            "127/127 [==============================] - 6s 50ms/step - loss: 1.3694 - accuracy: 0.4599 - val_loss: 1.4100 - val_accuracy: 0.4700\n",
            "Epoch 605/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3866 - accuracy: 0.4688 - val_loss: 1.4114 - val_accuracy: 0.4538\n",
            "Epoch 606/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3807 - accuracy: 0.4633 - val_loss: 1.4074 - val_accuracy: 0.4677\n",
            "Epoch 607/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3702 - accuracy: 0.4658 - val_loss: 1.4017 - val_accuracy: 0.4700\n",
            "Epoch 608/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3762 - accuracy: 0.4767 - val_loss: 1.4111 - val_accuracy: 0.4538\n",
            "Epoch 609/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3736 - accuracy: 0.4787 - val_loss: 1.4107 - val_accuracy: 0.4538\n",
            "Epoch 610/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3638 - accuracy: 0.4698 - val_loss: 1.4225 - val_accuracy: 0.4596\n",
            "Epoch 611/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3704 - accuracy: 0.4628 - val_loss: 1.4106 - val_accuracy: 0.4607\n",
            "Epoch 612/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3707 - accuracy: 0.4643 - val_loss: 1.4087 - val_accuracy: 0.4607\n",
            "Epoch 613/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3577 - accuracy: 0.4722 - val_loss: 1.4083 - val_accuracy: 0.4619\n",
            "Epoch 614/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3591 - accuracy: 0.4713 - val_loss: 1.4034 - val_accuracy: 0.4584\n",
            "Epoch 615/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3634 - accuracy: 0.4782 - val_loss: 1.4035 - val_accuracy: 0.4596\n",
            "Epoch 616/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.3747 - accuracy: 0.4658 - val_loss: 1.4017 - val_accuracy: 0.4677\n",
            "Epoch 617/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3711 - accuracy: 0.4648 - val_loss: 1.4089 - val_accuracy: 0.4642\n",
            "Epoch 618/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3586 - accuracy: 0.4737 - val_loss: 1.4114 - val_accuracy: 0.4584\n",
            "Epoch 619/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3627 - accuracy: 0.4718 - val_loss: 1.4019 - val_accuracy: 0.4607\n",
            "Epoch 620/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3591 - accuracy: 0.4628 - val_loss: 1.4056 - val_accuracy: 0.4538\n",
            "Epoch 621/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3745 - accuracy: 0.4727 - val_loss: 1.3971 - val_accuracy: 0.4550\n",
            "Epoch 622/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.3707 - accuracy: 0.4727 - val_loss: 1.3980 - val_accuracy: 0.4654\n",
            "Epoch 623/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.3778 - accuracy: 0.4643 - val_loss: 1.4139 - val_accuracy: 0.4607\n",
            "Epoch 624/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3675 - accuracy: 0.4643 - val_loss: 1.4152 - val_accuracy: 0.4607\n",
            "Epoch 625/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3656 - accuracy: 0.4767 - val_loss: 1.4028 - val_accuracy: 0.4573\n",
            "Epoch 626/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3622 - accuracy: 0.4792 - val_loss: 1.4045 - val_accuracy: 0.4734\n",
            "Epoch 627/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3547 - accuracy: 0.4663 - val_loss: 1.4042 - val_accuracy: 0.4573\n",
            "Epoch 628/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3601 - accuracy: 0.4742 - val_loss: 1.3978 - val_accuracy: 0.4734\n",
            "Epoch 629/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3607 - accuracy: 0.4713 - val_loss: 1.4086 - val_accuracy: 0.4573\n",
            "Epoch 630/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3590 - accuracy: 0.4767 - val_loss: 1.4032 - val_accuracy: 0.4607\n",
            "Epoch 631/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3638 - accuracy: 0.4812 - val_loss: 1.4034 - val_accuracy: 0.4584\n",
            "Epoch 632/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.3663 - accuracy: 0.4708 - val_loss: 1.3962 - val_accuracy: 0.4688\n",
            "Epoch 633/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3617 - accuracy: 0.4628 - val_loss: 1.3987 - val_accuracy: 0.4700\n",
            "Epoch 634/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3618 - accuracy: 0.4658 - val_loss: 1.4084 - val_accuracy: 0.4665\n",
            "Epoch 635/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3598 - accuracy: 0.4638 - val_loss: 1.3993 - val_accuracy: 0.4596\n",
            "Epoch 636/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3562 - accuracy: 0.4767 - val_loss: 1.4089 - val_accuracy: 0.4584\n",
            "Epoch 637/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3456 - accuracy: 0.4777 - val_loss: 1.3976 - val_accuracy: 0.4561\n",
            "Epoch 638/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3562 - accuracy: 0.4841 - val_loss: 1.4150 - val_accuracy: 0.4642\n",
            "Epoch 639/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3646 - accuracy: 0.4732 - val_loss: 1.3910 - val_accuracy: 0.4665\n",
            "Epoch 640/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3429 - accuracy: 0.4856 - val_loss: 1.3992 - val_accuracy: 0.4815\n",
            "Epoch 641/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3483 - accuracy: 0.4718 - val_loss: 1.4074 - val_accuracy: 0.4677\n",
            "Epoch 642/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3621 - accuracy: 0.4752 - val_loss: 1.3952 - val_accuracy: 0.4723\n",
            "Epoch 643/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3539 - accuracy: 0.4832 - val_loss: 1.3962 - val_accuracy: 0.4630\n",
            "Epoch 644/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3436 - accuracy: 0.4732 - val_loss: 1.4011 - val_accuracy: 0.4677\n",
            "Epoch 645/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3604 - accuracy: 0.4752 - val_loss: 1.4029 - val_accuracy: 0.4561\n",
            "Epoch 646/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3550 - accuracy: 0.4906 - val_loss: 1.3933 - val_accuracy: 0.4700\n",
            "Epoch 647/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3397 - accuracy: 0.4807 - val_loss: 1.3977 - val_accuracy: 0.4642\n",
            "Epoch 648/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3498 - accuracy: 0.4856 - val_loss: 1.4119 - val_accuracy: 0.4642\n",
            "Epoch 649/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3539 - accuracy: 0.4698 - val_loss: 1.3938 - val_accuracy: 0.4711\n",
            "Epoch 650/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3590 - accuracy: 0.4668 - val_loss: 1.3907 - val_accuracy: 0.4746\n",
            "Epoch 651/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3493 - accuracy: 0.4827 - val_loss: 1.4005 - val_accuracy: 0.4688\n",
            "Epoch 652/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3674 - accuracy: 0.4663 - val_loss: 1.4014 - val_accuracy: 0.4619\n",
            "Epoch 653/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3513 - accuracy: 0.4633 - val_loss: 1.3908 - val_accuracy: 0.4711\n",
            "Epoch 654/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3415 - accuracy: 0.4817 - val_loss: 1.3933 - val_accuracy: 0.4619\n",
            "Epoch 655/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3620 - accuracy: 0.4782 - val_loss: 1.3972 - val_accuracy: 0.4665\n",
            "Epoch 656/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3581 - accuracy: 0.4752 - val_loss: 1.3942 - val_accuracy: 0.4619\n",
            "Epoch 657/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3463 - accuracy: 0.4752 - val_loss: 1.3910 - val_accuracy: 0.4630\n",
            "Epoch 658/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3415 - accuracy: 0.4832 - val_loss: 1.3922 - val_accuracy: 0.4607\n",
            "Epoch 659/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3464 - accuracy: 0.4737 - val_loss: 1.4004 - val_accuracy: 0.4630\n",
            "Epoch 660/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3561 - accuracy: 0.4668 - val_loss: 1.3896 - val_accuracy: 0.4711\n",
            "Epoch 661/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3479 - accuracy: 0.4807 - val_loss: 1.3884 - val_accuracy: 0.4619\n",
            "Epoch 662/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3500 - accuracy: 0.4767 - val_loss: 1.3930 - val_accuracy: 0.4607\n",
            "Epoch 663/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3361 - accuracy: 0.4797 - val_loss: 1.3900 - val_accuracy: 0.4573\n",
            "Epoch 664/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3539 - accuracy: 0.4663 - val_loss: 1.3858 - val_accuracy: 0.4746\n",
            "Epoch 665/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3485 - accuracy: 0.4727 - val_loss: 1.3900 - val_accuracy: 0.4665\n",
            "Epoch 666/1000\n",
            "127/127 [==============================] - 6s 51ms/step - loss: 1.3432 - accuracy: 0.4846 - val_loss: 1.4072 - val_accuracy: 0.4619\n",
            "Epoch 667/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3394 - accuracy: 0.4841 - val_loss: 1.3906 - val_accuracy: 0.4677\n",
            "Epoch 668/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3305 - accuracy: 0.4856 - val_loss: 1.3860 - val_accuracy: 0.4642\n",
            "Epoch 669/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3486 - accuracy: 0.4787 - val_loss: 1.3978 - val_accuracy: 0.4677\n",
            "Epoch 670/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3238 - accuracy: 0.4891 - val_loss: 1.3984 - val_accuracy: 0.4734\n",
            "Epoch 671/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3335 - accuracy: 0.4856 - val_loss: 1.3830 - val_accuracy: 0.4746\n",
            "Epoch 672/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3564 - accuracy: 0.4792 - val_loss: 1.3850 - val_accuracy: 0.4607\n",
            "Epoch 673/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3410 - accuracy: 0.4866 - val_loss: 1.3843 - val_accuracy: 0.4665\n",
            "Epoch 674/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3260 - accuracy: 0.4955 - val_loss: 1.3876 - val_accuracy: 0.4677\n",
            "Epoch 675/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3506 - accuracy: 0.4718 - val_loss: 1.3841 - val_accuracy: 0.4677\n",
            "Epoch 676/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3343 - accuracy: 0.4921 - val_loss: 1.4012 - val_accuracy: 0.4619\n",
            "Epoch 677/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3308 - accuracy: 0.4871 - val_loss: 1.3817 - val_accuracy: 0.4792\n",
            "Epoch 678/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3281 - accuracy: 0.4807 - val_loss: 1.3864 - val_accuracy: 0.4711\n",
            "Epoch 679/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3499 - accuracy: 0.4678 - val_loss: 1.3862 - val_accuracy: 0.4677\n",
            "Epoch 680/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3366 - accuracy: 0.4827 - val_loss: 1.3852 - val_accuracy: 0.4734\n",
            "Epoch 681/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.3374 - accuracy: 0.4797 - val_loss: 1.3850 - val_accuracy: 0.4677\n",
            "Epoch 682/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3326 - accuracy: 0.4871 - val_loss: 1.3822 - val_accuracy: 0.4700\n",
            "Epoch 683/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3275 - accuracy: 0.4851 - val_loss: 1.3908 - val_accuracy: 0.4573\n",
            "Epoch 684/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3340 - accuracy: 0.4901 - val_loss: 1.3880 - val_accuracy: 0.4665\n",
            "Epoch 685/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.3479 - accuracy: 0.4866 - val_loss: 1.3813 - val_accuracy: 0.4758\n",
            "Epoch 686/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3419 - accuracy: 0.4797 - val_loss: 1.3931 - val_accuracy: 0.4677\n",
            "Epoch 687/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3360 - accuracy: 0.4782 - val_loss: 1.3837 - val_accuracy: 0.4665\n",
            "Epoch 688/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3362 - accuracy: 0.4752 - val_loss: 1.3832 - val_accuracy: 0.4711\n",
            "Epoch 689/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3334 - accuracy: 0.4851 - val_loss: 1.3772 - val_accuracy: 0.4723\n",
            "Epoch 690/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3383 - accuracy: 0.4757 - val_loss: 1.3876 - val_accuracy: 0.4654\n",
            "Epoch 691/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3284 - accuracy: 0.4807 - val_loss: 1.4044 - val_accuracy: 0.4607\n",
            "Epoch 692/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3282 - accuracy: 0.4970 - val_loss: 1.3805 - val_accuracy: 0.4781\n",
            "Epoch 693/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3350 - accuracy: 0.4817 - val_loss: 1.3827 - val_accuracy: 0.4711\n",
            "Epoch 694/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3340 - accuracy: 0.4802 - val_loss: 1.3780 - val_accuracy: 0.4711\n",
            "Epoch 695/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3182 - accuracy: 0.4995 - val_loss: 1.3847 - val_accuracy: 0.4630\n",
            "Epoch 696/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3162 - accuracy: 0.4941 - val_loss: 1.3764 - val_accuracy: 0.4746\n",
            "Epoch 697/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3164 - accuracy: 0.4822 - val_loss: 1.3861 - val_accuracy: 0.4723\n",
            "Epoch 698/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3238 - accuracy: 0.4955 - val_loss: 1.3881 - val_accuracy: 0.4711\n",
            "Epoch 699/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3222 - accuracy: 0.4886 - val_loss: 1.3825 - val_accuracy: 0.4746\n",
            "Epoch 700/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3233 - accuracy: 0.4832 - val_loss: 1.3815 - val_accuracy: 0.4700\n",
            "Epoch 701/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3430 - accuracy: 0.4772 - val_loss: 1.3787 - val_accuracy: 0.4781\n",
            "Epoch 702/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3144 - accuracy: 0.4921 - val_loss: 1.3866 - val_accuracy: 0.4630\n",
            "Epoch 703/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3305 - accuracy: 0.4827 - val_loss: 1.3836 - val_accuracy: 0.4746\n",
            "Epoch 704/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3164 - accuracy: 0.4886 - val_loss: 1.3739 - val_accuracy: 0.4734\n",
            "Epoch 705/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3354 - accuracy: 0.4802 - val_loss: 1.3951 - val_accuracy: 0.4654\n",
            "Epoch 706/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3290 - accuracy: 0.4856 - val_loss: 1.3742 - val_accuracy: 0.4711\n",
            "Epoch 707/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3146 - accuracy: 0.4827 - val_loss: 1.3759 - val_accuracy: 0.4746\n",
            "Epoch 708/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3110 - accuracy: 0.4911 - val_loss: 1.3791 - val_accuracy: 0.4654\n",
            "Epoch 709/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3256 - accuracy: 0.4792 - val_loss: 1.3769 - val_accuracy: 0.4711\n",
            "Epoch 710/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3233 - accuracy: 0.4747 - val_loss: 1.3790 - val_accuracy: 0.4700\n",
            "Epoch 711/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3099 - accuracy: 0.4921 - val_loss: 1.3770 - val_accuracy: 0.4630\n",
            "Epoch 712/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3291 - accuracy: 0.4876 - val_loss: 1.3886 - val_accuracy: 0.4723\n",
            "Epoch 713/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3176 - accuracy: 0.4866 - val_loss: 1.3760 - val_accuracy: 0.4654\n",
            "Epoch 714/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.3259 - accuracy: 0.4722 - val_loss: 1.3790 - val_accuracy: 0.4630\n",
            "Epoch 715/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.3273 - accuracy: 0.4777 - val_loss: 1.3730 - val_accuracy: 0.4665\n",
            "Epoch 716/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3265 - accuracy: 0.4876 - val_loss: 1.3781 - val_accuracy: 0.4596\n",
            "Epoch 717/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3254 - accuracy: 0.4886 - val_loss: 1.3795 - val_accuracy: 0.4734\n",
            "Epoch 718/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3180 - accuracy: 0.4921 - val_loss: 1.3711 - val_accuracy: 0.4688\n",
            "Epoch 719/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3250 - accuracy: 0.4881 - val_loss: 1.3815 - val_accuracy: 0.4584\n",
            "Epoch 720/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3049 - accuracy: 0.4990 - val_loss: 1.3760 - val_accuracy: 0.4711\n",
            "Epoch 721/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3036 - accuracy: 0.4985 - val_loss: 1.3696 - val_accuracy: 0.4746\n",
            "Epoch 722/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3191 - accuracy: 0.4965 - val_loss: 1.3751 - val_accuracy: 0.4711\n",
            "Epoch 723/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3296 - accuracy: 0.4965 - val_loss: 1.3785 - val_accuracy: 0.4654\n",
            "Epoch 724/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3162 - accuracy: 0.4926 - val_loss: 1.3745 - val_accuracy: 0.4711\n",
            "Epoch 725/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3177 - accuracy: 0.4866 - val_loss: 1.3905 - val_accuracy: 0.4642\n",
            "Epoch 726/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3267 - accuracy: 0.4802 - val_loss: 1.3675 - val_accuracy: 0.4792\n",
            "Epoch 727/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3165 - accuracy: 0.4772 - val_loss: 1.3676 - val_accuracy: 0.4746\n",
            "Epoch 728/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3162 - accuracy: 0.4926 - val_loss: 1.3733 - val_accuracy: 0.4688\n",
            "Epoch 729/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2968 - accuracy: 0.4985 - val_loss: 1.3677 - val_accuracy: 0.4758\n",
            "Epoch 730/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3037 - accuracy: 0.4941 - val_loss: 1.3682 - val_accuracy: 0.4723\n",
            "Epoch 731/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.3087 - accuracy: 0.4960 - val_loss: 1.3952 - val_accuracy: 0.4688\n",
            "Epoch 732/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3136 - accuracy: 0.4881 - val_loss: 1.3699 - val_accuracy: 0.4815\n",
            "Epoch 733/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3147 - accuracy: 0.4926 - val_loss: 1.3635 - val_accuracy: 0.4769\n",
            "Epoch 734/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3088 - accuracy: 0.4975 - val_loss: 1.3754 - val_accuracy: 0.4642\n",
            "Epoch 735/1000\n",
            "127/127 [==============================] - 7s 52ms/step - loss: 1.3118 - accuracy: 0.4891 - val_loss: 1.3750 - val_accuracy: 0.4688\n",
            "Epoch 736/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3088 - accuracy: 0.4871 - val_loss: 1.3774 - val_accuracy: 0.4630\n",
            "Epoch 737/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.2993 - accuracy: 0.4817 - val_loss: 1.3641 - val_accuracy: 0.4723\n",
            "Epoch 738/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3146 - accuracy: 0.4861 - val_loss: 1.3692 - val_accuracy: 0.4677\n",
            "Epoch 739/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3068 - accuracy: 0.5030 - val_loss: 1.3747 - val_accuracy: 0.4769\n",
            "Epoch 740/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.3068 - accuracy: 0.4901 - val_loss: 1.3660 - val_accuracy: 0.4711\n",
            "Epoch 741/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2978 - accuracy: 0.4871 - val_loss: 1.3829 - val_accuracy: 0.4677\n",
            "Epoch 742/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3183 - accuracy: 0.4827 - val_loss: 1.3727 - val_accuracy: 0.4654\n",
            "Epoch 743/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3046 - accuracy: 0.4886 - val_loss: 1.3816 - val_accuracy: 0.4619\n",
            "Epoch 744/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2957 - accuracy: 0.4955 - val_loss: 1.3659 - val_accuracy: 0.4688\n",
            "Epoch 745/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3007 - accuracy: 0.4896 - val_loss: 1.3662 - val_accuracy: 0.4700\n",
            "Epoch 746/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3116 - accuracy: 0.4950 - val_loss: 1.3621 - val_accuracy: 0.4711\n",
            "Epoch 747/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3079 - accuracy: 0.4960 - val_loss: 1.3771 - val_accuracy: 0.4642\n",
            "Epoch 748/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.3144 - accuracy: 0.4812 - val_loss: 1.3745 - val_accuracy: 0.4596\n",
            "Epoch 749/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.3106 - accuracy: 0.4926 - val_loss: 1.3638 - val_accuracy: 0.4792\n",
            "Epoch 750/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2949 - accuracy: 0.4861 - val_loss: 1.3600 - val_accuracy: 0.4758\n",
            "Epoch 751/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.3012 - accuracy: 0.4832 - val_loss: 1.3631 - val_accuracy: 0.4654\n",
            "Epoch 752/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2926 - accuracy: 0.4891 - val_loss: 1.3668 - val_accuracy: 0.4746\n",
            "Epoch 753/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3085 - accuracy: 0.4916 - val_loss: 1.3625 - val_accuracy: 0.4688\n",
            "Epoch 754/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.3018 - accuracy: 0.4921 - val_loss: 1.3712 - val_accuracy: 0.4723\n",
            "Epoch 755/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2965 - accuracy: 0.4955 - val_loss: 1.3604 - val_accuracy: 0.4769\n",
            "Epoch 756/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2994 - accuracy: 0.5074 - val_loss: 1.3668 - val_accuracy: 0.4711\n",
            "Epoch 757/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3087 - accuracy: 0.4891 - val_loss: 1.3641 - val_accuracy: 0.4746\n",
            "Epoch 758/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2851 - accuracy: 0.5084 - val_loss: 1.3812 - val_accuracy: 0.4642\n",
            "Epoch 759/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.3007 - accuracy: 0.4955 - val_loss: 1.3610 - val_accuracy: 0.4711\n",
            "Epoch 760/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2950 - accuracy: 0.4941 - val_loss: 1.3655 - val_accuracy: 0.4723\n",
            "Epoch 761/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.3051 - accuracy: 0.4970 - val_loss: 1.3633 - val_accuracy: 0.4723\n",
            "Epoch 762/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.3011 - accuracy: 0.4955 - val_loss: 1.3826 - val_accuracy: 0.4630\n",
            "Epoch 763/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2858 - accuracy: 0.5010 - val_loss: 1.3558 - val_accuracy: 0.4804\n",
            "Epoch 764/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2832 - accuracy: 0.4891 - val_loss: 1.3836 - val_accuracy: 0.4619\n",
            "Epoch 765/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2937 - accuracy: 0.5035 - val_loss: 1.3755 - val_accuracy: 0.4677\n",
            "Epoch 766/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.3015 - accuracy: 0.4926 - val_loss: 1.3586 - val_accuracy: 0.4700\n",
            "Epoch 767/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2944 - accuracy: 0.4995 - val_loss: 1.3604 - val_accuracy: 0.4723\n",
            "Epoch 768/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2862 - accuracy: 0.4896 - val_loss: 1.3766 - val_accuracy: 0.4607\n",
            "Epoch 769/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2936 - accuracy: 0.5109 - val_loss: 1.3590 - val_accuracy: 0.4700\n",
            "Epoch 770/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2871 - accuracy: 0.5005 - val_loss: 1.3509 - val_accuracy: 0.4827\n",
            "Epoch 771/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2982 - accuracy: 0.4960 - val_loss: 1.3626 - val_accuracy: 0.4746\n",
            "Epoch 772/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2931 - accuracy: 0.4965 - val_loss: 1.3545 - val_accuracy: 0.4723\n",
            "Epoch 773/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.2854 - accuracy: 0.4980 - val_loss: 1.3621 - val_accuracy: 0.4700\n",
            "Epoch 774/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2869 - accuracy: 0.5030 - val_loss: 1.3574 - val_accuracy: 0.4654\n",
            "Epoch 775/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2996 - accuracy: 0.4926 - val_loss: 1.3523 - val_accuracy: 0.4734\n",
            "Epoch 776/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2891 - accuracy: 0.5020 - val_loss: 1.3530 - val_accuracy: 0.4769\n",
            "Epoch 777/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.3014 - accuracy: 0.4955 - val_loss: 1.3612 - val_accuracy: 0.4665\n",
            "Epoch 778/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2887 - accuracy: 0.5025 - val_loss: 1.3708 - val_accuracy: 0.4619\n",
            "Epoch 779/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2928 - accuracy: 0.4921 - val_loss: 1.3559 - val_accuracy: 0.4700\n",
            "Epoch 780/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2723 - accuracy: 0.5025 - val_loss: 1.3608 - val_accuracy: 0.4700\n",
            "Epoch 781/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2849 - accuracy: 0.5104 - val_loss: 1.3497 - val_accuracy: 0.4827\n",
            "Epoch 782/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2936 - accuracy: 0.4896 - val_loss: 1.3617 - val_accuracy: 0.4746\n",
            "Epoch 783/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2916 - accuracy: 0.4955 - val_loss: 1.3501 - val_accuracy: 0.4815\n",
            "Epoch 784/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2891 - accuracy: 0.5069 - val_loss: 1.3536 - val_accuracy: 0.4723\n",
            "Epoch 785/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2619 - accuracy: 0.5178 - val_loss: 1.3594 - val_accuracy: 0.4769\n",
            "Epoch 786/1000\n",
            "127/127 [==============================] - 9s 67ms/step - loss: 1.2845 - accuracy: 0.4950 - val_loss: 1.3547 - val_accuracy: 0.4734\n",
            "Epoch 787/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2861 - accuracy: 0.5030 - val_loss: 1.3532 - val_accuracy: 0.4734\n",
            "Epoch 788/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.3012 - accuracy: 0.4955 - val_loss: 1.3542 - val_accuracy: 0.4781\n",
            "Epoch 789/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2902 - accuracy: 0.5069 - val_loss: 1.3533 - val_accuracy: 0.4700\n",
            "Epoch 790/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2908 - accuracy: 0.4911 - val_loss: 1.3546 - val_accuracy: 0.4711\n",
            "Epoch 791/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2735 - accuracy: 0.5050 - val_loss: 1.3467 - val_accuracy: 0.4908\n",
            "Epoch 792/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2877 - accuracy: 0.4936 - val_loss: 1.3469 - val_accuracy: 0.4758\n",
            "Epoch 793/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2724 - accuracy: 0.5030 - val_loss: 1.3544 - val_accuracy: 0.4850\n",
            "Epoch 794/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2824 - accuracy: 0.5055 - val_loss: 1.3526 - val_accuracy: 0.4838\n",
            "Epoch 795/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2835 - accuracy: 0.4975 - val_loss: 1.3456 - val_accuracy: 0.4804\n",
            "Epoch 796/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2804 - accuracy: 0.5089 - val_loss: 1.3464 - val_accuracy: 0.4861\n",
            "Epoch 797/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2825 - accuracy: 0.4921 - val_loss: 1.3476 - val_accuracy: 0.4769\n",
            "Epoch 798/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2727 - accuracy: 0.5050 - val_loss: 1.3454 - val_accuracy: 0.4792\n",
            "Epoch 799/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2739 - accuracy: 0.4995 - val_loss: 1.3490 - val_accuracy: 0.4838\n",
            "Epoch 800/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2675 - accuracy: 0.5069 - val_loss: 1.3822 - val_accuracy: 0.4584\n",
            "Epoch 801/1000\n",
            "127/127 [==============================] - 9s 69ms/step - loss: 1.2859 - accuracy: 0.5005 - val_loss: 1.3489 - val_accuracy: 0.4827\n",
            "Epoch 802/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2863 - accuracy: 0.4960 - val_loss: 1.3560 - val_accuracy: 0.4781\n",
            "Epoch 803/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2640 - accuracy: 0.5059 - val_loss: 1.3484 - val_accuracy: 0.4861\n",
            "Epoch 804/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2748 - accuracy: 0.5035 - val_loss: 1.3527 - val_accuracy: 0.4607\n",
            "Epoch 805/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2693 - accuracy: 0.5069 - val_loss: 1.3699 - val_accuracy: 0.4596\n",
            "Epoch 806/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2819 - accuracy: 0.5055 - val_loss: 1.3569 - val_accuracy: 0.4677\n",
            "Epoch 807/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.2864 - accuracy: 0.5069 - val_loss: 1.3816 - val_accuracy: 0.4584\n",
            "Epoch 808/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2809 - accuracy: 0.4995 - val_loss: 1.3549 - val_accuracy: 0.4734\n",
            "Epoch 809/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2788 - accuracy: 0.4916 - val_loss: 1.3537 - val_accuracy: 0.4873\n",
            "Epoch 810/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2774 - accuracy: 0.5124 - val_loss: 1.3450 - val_accuracy: 0.4711\n",
            "Epoch 811/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2839 - accuracy: 0.5084 - val_loss: 1.3789 - val_accuracy: 0.4607\n",
            "Epoch 812/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2688 - accuracy: 0.5064 - val_loss: 1.3455 - val_accuracy: 0.4804\n",
            "Epoch 813/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2711 - accuracy: 0.5069 - val_loss: 1.3436 - val_accuracy: 0.4804\n",
            "Epoch 814/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2674 - accuracy: 0.5089 - val_loss: 1.3458 - val_accuracy: 0.4873\n",
            "Epoch 815/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2801 - accuracy: 0.5015 - val_loss: 1.3482 - val_accuracy: 0.4677\n",
            "Epoch 816/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2809 - accuracy: 0.4970 - val_loss: 1.3417 - val_accuracy: 0.4573\n",
            "Epoch 817/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2741 - accuracy: 0.4985 - val_loss: 1.3756 - val_accuracy: 0.4619\n",
            "Epoch 818/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2674 - accuracy: 0.5055 - val_loss: 1.3604 - val_accuracy: 0.4654\n",
            "Epoch 819/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2567 - accuracy: 0.5055 - val_loss: 1.3476 - val_accuracy: 0.4746\n",
            "Epoch 820/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2759 - accuracy: 0.5074 - val_loss: 1.3487 - val_accuracy: 0.4619\n",
            "Epoch 821/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2603 - accuracy: 0.5134 - val_loss: 1.3409 - val_accuracy: 0.4815\n",
            "Epoch 822/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2615 - accuracy: 0.5183 - val_loss: 1.3420 - val_accuracy: 0.4596\n",
            "Epoch 823/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2608 - accuracy: 0.5178 - val_loss: 1.3495 - val_accuracy: 0.4527\n",
            "Epoch 824/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2759 - accuracy: 0.5035 - val_loss: 1.3466 - val_accuracy: 0.4607\n",
            "Epoch 825/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2576 - accuracy: 0.5089 - val_loss: 1.4127 - val_accuracy: 0.4434\n",
            "Epoch 826/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2728 - accuracy: 0.5025 - val_loss: 1.3539 - val_accuracy: 0.4781\n",
            "Epoch 827/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2730 - accuracy: 0.5045 - val_loss: 1.3536 - val_accuracy: 0.4711\n",
            "Epoch 828/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.2678 - accuracy: 0.5144 - val_loss: 1.3424 - val_accuracy: 0.4619\n",
            "Epoch 829/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.2669 - accuracy: 0.5084 - val_loss: 1.3510 - val_accuracy: 0.4654\n",
            "Epoch 830/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2675 - accuracy: 0.5055 - val_loss: 1.3493 - val_accuracy: 0.4758\n",
            "Epoch 831/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2656 - accuracy: 0.5010 - val_loss: 1.3462 - val_accuracy: 0.4688\n",
            "Epoch 832/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2720 - accuracy: 0.5079 - val_loss: 1.3374 - val_accuracy: 0.4815\n",
            "Epoch 833/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2751 - accuracy: 0.5084 - val_loss: 1.3348 - val_accuracy: 0.4873\n",
            "Epoch 834/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2656 - accuracy: 0.5198 - val_loss: 1.3440 - val_accuracy: 0.4896\n",
            "Epoch 835/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2485 - accuracy: 0.5129 - val_loss: 1.3461 - val_accuracy: 0.4804\n",
            "Epoch 836/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2697 - accuracy: 0.5040 - val_loss: 1.3438 - val_accuracy: 0.4688\n",
            "Epoch 837/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2702 - accuracy: 0.5064 - val_loss: 1.3395 - val_accuracy: 0.4746\n",
            "Epoch 838/1000\n",
            "127/127 [==============================] - 7s 54ms/step - loss: 1.2730 - accuracy: 0.5074 - val_loss: 1.3434 - val_accuracy: 0.4838\n",
            "Epoch 839/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2540 - accuracy: 0.5164 - val_loss: 1.3382 - val_accuracy: 0.4873\n",
            "Epoch 840/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2635 - accuracy: 0.5134 - val_loss: 1.3420 - val_accuracy: 0.4642\n",
            "Epoch 841/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2690 - accuracy: 0.5059 - val_loss: 1.3349 - val_accuracy: 0.4758\n",
            "Epoch 842/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2565 - accuracy: 0.5149 - val_loss: 1.3440 - val_accuracy: 0.4596\n",
            "Epoch 843/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2478 - accuracy: 0.5248 - val_loss: 1.3381 - val_accuracy: 0.4769\n",
            "Epoch 844/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2614 - accuracy: 0.5045 - val_loss: 1.3403 - val_accuracy: 0.4827\n",
            "Epoch 845/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2608 - accuracy: 0.5010 - val_loss: 1.3464 - val_accuracy: 0.4827\n",
            "Epoch 846/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2680 - accuracy: 0.5134 - val_loss: 1.3318 - val_accuracy: 0.4723\n",
            "Epoch 847/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2558 - accuracy: 0.5084 - val_loss: 1.3362 - val_accuracy: 0.4850\n",
            "Epoch 848/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2678 - accuracy: 0.5069 - val_loss: 1.3449 - val_accuracy: 0.4723\n",
            "Epoch 849/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2507 - accuracy: 0.5178 - val_loss: 1.3376 - val_accuracy: 0.4630\n",
            "Epoch 850/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2479 - accuracy: 0.5168 - val_loss: 1.3508 - val_accuracy: 0.4642\n",
            "Epoch 851/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2537 - accuracy: 0.5168 - val_loss: 1.3508 - val_accuracy: 0.4781\n",
            "Epoch 852/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2589 - accuracy: 0.5119 - val_loss: 1.3319 - val_accuracy: 0.4804\n",
            "Epoch 853/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2568 - accuracy: 0.5114 - val_loss: 1.3330 - val_accuracy: 0.4734\n",
            "Epoch 854/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2486 - accuracy: 0.5159 - val_loss: 1.3300 - val_accuracy: 0.4850\n",
            "Epoch 855/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2481 - accuracy: 0.5253 - val_loss: 1.3324 - val_accuracy: 0.4792\n",
            "Epoch 856/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2417 - accuracy: 0.5273 - val_loss: 1.3340 - val_accuracy: 0.4700\n",
            "Epoch 857/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2546 - accuracy: 0.5104 - val_loss: 1.3299 - val_accuracy: 0.4838\n",
            "Epoch 858/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2621 - accuracy: 0.5223 - val_loss: 1.3365 - val_accuracy: 0.4654\n",
            "Epoch 859/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2578 - accuracy: 0.5119 - val_loss: 1.3424 - val_accuracy: 0.4677\n",
            "Epoch 860/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2554 - accuracy: 0.5074 - val_loss: 1.3370 - val_accuracy: 0.4654\n",
            "Epoch 861/1000\n",
            "127/127 [==============================] - 8s 65ms/step - loss: 1.2548 - accuracy: 0.5188 - val_loss: 1.3378 - val_accuracy: 0.4654\n",
            "Epoch 862/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2451 - accuracy: 0.5164 - val_loss: 1.3365 - val_accuracy: 0.4896\n",
            "Epoch 863/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2458 - accuracy: 0.5089 - val_loss: 1.3316 - val_accuracy: 0.4769\n",
            "Epoch 864/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2416 - accuracy: 0.5208 - val_loss: 1.3301 - val_accuracy: 0.4688\n",
            "Epoch 865/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2458 - accuracy: 0.5312 - val_loss: 1.3307 - val_accuracy: 0.4815\n",
            "Epoch 866/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2514 - accuracy: 0.5178 - val_loss: 1.3473 - val_accuracy: 0.4838\n",
            "Epoch 867/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2478 - accuracy: 0.5228 - val_loss: 1.3420 - val_accuracy: 0.4700\n",
            "Epoch 868/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2520 - accuracy: 0.5213 - val_loss: 1.3258 - val_accuracy: 0.4769\n",
            "Epoch 869/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2406 - accuracy: 0.5223 - val_loss: 1.3260 - val_accuracy: 0.4746\n",
            "Epoch 870/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2526 - accuracy: 0.5129 - val_loss: 1.3682 - val_accuracy: 0.4619\n",
            "Epoch 871/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2463 - accuracy: 0.5218 - val_loss: 1.3256 - val_accuracy: 0.4885\n",
            "Epoch 872/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2552 - accuracy: 0.5134 - val_loss: 1.3278 - val_accuracy: 0.4746\n",
            "Epoch 873/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2432 - accuracy: 0.5139 - val_loss: 1.3294 - val_accuracy: 0.4665\n",
            "Epoch 874/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2520 - accuracy: 0.5119 - val_loss: 1.3282 - val_accuracy: 0.4815\n",
            "Epoch 875/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2599 - accuracy: 0.5055 - val_loss: 1.3291 - val_accuracy: 0.4792\n",
            "Epoch 876/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2517 - accuracy: 0.5278 - val_loss: 1.3250 - val_accuracy: 0.4861\n",
            "Epoch 877/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2465 - accuracy: 0.5104 - val_loss: 1.3322 - val_accuracy: 0.4734\n",
            "Epoch 878/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2404 - accuracy: 0.5173 - val_loss: 1.3377 - val_accuracy: 0.4677\n",
            "Epoch 879/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2391 - accuracy: 0.5253 - val_loss: 1.3243 - val_accuracy: 0.4769\n",
            "Epoch 880/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2362 - accuracy: 0.5173 - val_loss: 1.3329 - val_accuracy: 0.4885\n",
            "Epoch 881/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2442 - accuracy: 0.5228 - val_loss: 1.3241 - val_accuracy: 0.4723\n",
            "Epoch 882/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2388 - accuracy: 0.5178 - val_loss: 1.3349 - val_accuracy: 0.4838\n",
            "Epoch 883/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2553 - accuracy: 0.5129 - val_loss: 1.3322 - val_accuracy: 0.4815\n",
            "Epoch 884/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2522 - accuracy: 0.5104 - val_loss: 1.3241 - val_accuracy: 0.4815\n",
            "Epoch 885/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2390 - accuracy: 0.5238 - val_loss: 1.3363 - val_accuracy: 0.4769\n",
            "Epoch 886/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2473 - accuracy: 0.5104 - val_loss: 1.3350 - val_accuracy: 0.4815\n",
            "Epoch 887/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2368 - accuracy: 0.5109 - val_loss: 1.3289 - val_accuracy: 0.4723\n",
            "Epoch 888/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2297 - accuracy: 0.5297 - val_loss: 1.3300 - val_accuracy: 0.4746\n",
            "Epoch 889/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2371 - accuracy: 0.5178 - val_loss: 1.3246 - val_accuracy: 0.4769\n",
            "Epoch 890/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2466 - accuracy: 0.5173 - val_loss: 1.3318 - val_accuracy: 0.4758\n",
            "Epoch 891/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2451 - accuracy: 0.5198 - val_loss: 1.3226 - val_accuracy: 0.4815\n",
            "Epoch 892/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2415 - accuracy: 0.5050 - val_loss: 1.3377 - val_accuracy: 0.4838\n",
            "Epoch 893/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2295 - accuracy: 0.5243 - val_loss: 1.3366 - val_accuracy: 0.4723\n",
            "Epoch 894/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2340 - accuracy: 0.5302 - val_loss: 1.3180 - val_accuracy: 0.4815\n",
            "Epoch 895/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2418 - accuracy: 0.5183 - val_loss: 1.3369 - val_accuracy: 0.4723\n",
            "Epoch 896/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2422 - accuracy: 0.5228 - val_loss: 1.3238 - val_accuracy: 0.4804\n",
            "Epoch 897/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2431 - accuracy: 0.5228 - val_loss: 1.3264 - val_accuracy: 0.4838\n",
            "Epoch 898/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2384 - accuracy: 0.5173 - val_loss: 1.3154 - val_accuracy: 0.4792\n",
            "Epoch 899/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2310 - accuracy: 0.5168 - val_loss: 1.3255 - val_accuracy: 0.4723\n",
            "Epoch 900/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2352 - accuracy: 0.5278 - val_loss: 1.3957 - val_accuracy: 0.4573\n",
            "Epoch 901/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2417 - accuracy: 0.5188 - val_loss: 1.3357 - val_accuracy: 0.4792\n",
            "Epoch 902/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2370 - accuracy: 0.5114 - val_loss: 1.3265 - val_accuracy: 0.4804\n",
            "Epoch 903/1000\n",
            "127/127 [==============================] - 7s 55ms/step - loss: 1.2228 - accuracy: 0.5387 - val_loss: 1.3278 - val_accuracy: 0.4746\n",
            "Epoch 904/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2206 - accuracy: 0.5203 - val_loss: 1.3335 - val_accuracy: 0.4677\n",
            "Epoch 905/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2290 - accuracy: 0.5347 - val_loss: 1.3181 - val_accuracy: 0.4792\n",
            "Epoch 906/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2424 - accuracy: 0.5119 - val_loss: 1.3297 - val_accuracy: 0.4885\n",
            "Epoch 907/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2203 - accuracy: 0.5292 - val_loss: 1.3269 - val_accuracy: 0.4827\n",
            "Epoch 908/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2326 - accuracy: 0.5282 - val_loss: 1.3467 - val_accuracy: 0.4792\n",
            "Epoch 909/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2321 - accuracy: 0.5357 - val_loss: 1.3251 - val_accuracy: 0.4746\n",
            "Epoch 910/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2292 - accuracy: 0.5233 - val_loss: 1.3236 - val_accuracy: 0.4838\n",
            "Epoch 911/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2386 - accuracy: 0.5213 - val_loss: 1.3335 - val_accuracy: 0.4746\n",
            "Epoch 912/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2329 - accuracy: 0.5278 - val_loss: 1.3258 - val_accuracy: 0.4723\n",
            "Epoch 913/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2549 - accuracy: 0.5228 - val_loss: 1.3240 - val_accuracy: 0.4838\n",
            "Epoch 914/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2197 - accuracy: 0.5233 - val_loss: 1.3199 - val_accuracy: 0.4723\n",
            "Epoch 915/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2459 - accuracy: 0.5382 - val_loss: 1.3349 - val_accuracy: 0.4746\n",
            "Epoch 916/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2303 - accuracy: 0.5282 - val_loss: 1.3173 - val_accuracy: 0.4758\n",
            "Epoch 917/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2350 - accuracy: 0.5208 - val_loss: 1.3193 - val_accuracy: 0.4769\n",
            "Epoch 918/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2292 - accuracy: 0.5213 - val_loss: 1.3141 - val_accuracy: 0.4827\n",
            "Epoch 919/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2146 - accuracy: 0.5352 - val_loss: 1.3211 - val_accuracy: 0.4804\n",
            "Epoch 920/1000\n",
            "127/127 [==============================] - 7s 56ms/step - loss: 1.2248 - accuracy: 0.5243 - val_loss: 1.3584 - val_accuracy: 0.4677\n",
            "Epoch 921/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2301 - accuracy: 0.5282 - val_loss: 1.3191 - val_accuracy: 0.4861\n",
            "Epoch 922/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2264 - accuracy: 0.5268 - val_loss: 1.3137 - val_accuracy: 0.4827\n",
            "Epoch 923/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2329 - accuracy: 0.5307 - val_loss: 1.3167 - val_accuracy: 0.4838\n",
            "Epoch 924/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2287 - accuracy: 0.5168 - val_loss: 1.3115 - val_accuracy: 0.4861\n",
            "Epoch 925/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2112 - accuracy: 0.5327 - val_loss: 1.3141 - val_accuracy: 0.4792\n",
            "Epoch 926/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2165 - accuracy: 0.5342 - val_loss: 1.3174 - val_accuracy: 0.4723\n",
            "Epoch 927/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2210 - accuracy: 0.5208 - val_loss: 1.3234 - val_accuracy: 0.4838\n",
            "Epoch 928/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2236 - accuracy: 0.5149 - val_loss: 1.3156 - val_accuracy: 0.4746\n",
            "Epoch 929/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.2330 - accuracy: 0.5248 - val_loss: 1.3233 - val_accuracy: 0.4804\n",
            "Epoch 930/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2216 - accuracy: 0.5233 - val_loss: 1.3158 - val_accuracy: 0.4781\n",
            "Epoch 931/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2175 - accuracy: 0.5337 - val_loss: 1.3097 - val_accuracy: 0.4781\n",
            "Epoch 932/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2141 - accuracy: 0.5268 - val_loss: 1.3097 - val_accuracy: 0.4942\n",
            "Epoch 933/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2244 - accuracy: 0.5357 - val_loss: 1.3141 - val_accuracy: 0.4758\n",
            "Epoch 934/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2267 - accuracy: 0.5248 - val_loss: 1.3161 - val_accuracy: 0.4850\n",
            "Epoch 935/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2286 - accuracy: 0.5129 - val_loss: 1.3135 - val_accuracy: 0.4827\n",
            "Epoch 936/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2112 - accuracy: 0.5332 - val_loss: 1.3148 - val_accuracy: 0.4758\n",
            "Epoch 937/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2088 - accuracy: 0.5337 - val_loss: 1.3273 - val_accuracy: 0.4838\n",
            "Epoch 938/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2311 - accuracy: 0.5164 - val_loss: 1.3099 - val_accuracy: 0.4781\n",
            "Epoch 939/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.1991 - accuracy: 0.5362 - val_loss: 1.3151 - val_accuracy: 0.4827\n",
            "Epoch 940/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2199 - accuracy: 0.5322 - val_loss: 1.3097 - val_accuracy: 0.4885\n",
            "Epoch 941/1000\n",
            "127/127 [==============================] - 9s 75ms/step - loss: 1.2064 - accuracy: 0.5486 - val_loss: 1.3091 - val_accuracy: 0.4850\n",
            "Epoch 942/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2034 - accuracy: 0.5372 - val_loss: 1.3078 - val_accuracy: 0.4850\n",
            "Epoch 943/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2247 - accuracy: 0.5377 - val_loss: 1.3125 - val_accuracy: 0.4942\n",
            "Epoch 944/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2136 - accuracy: 0.5362 - val_loss: 1.3113 - val_accuracy: 0.4873\n",
            "Epoch 945/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2121 - accuracy: 0.5213 - val_loss: 1.3087 - val_accuracy: 0.4850\n",
            "Epoch 946/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2122 - accuracy: 0.5203 - val_loss: 1.3062 - val_accuracy: 0.4815\n",
            "Epoch 947/1000\n",
            "127/127 [==============================] - 8s 64ms/step - loss: 1.2292 - accuracy: 0.5307 - val_loss: 1.3086 - val_accuracy: 0.4885\n",
            "Epoch 948/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2231 - accuracy: 0.5218 - val_loss: 1.3101 - val_accuracy: 0.4827\n",
            "Epoch 949/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2009 - accuracy: 0.5302 - val_loss: 1.3113 - val_accuracy: 0.4873\n",
            "Epoch 950/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2105 - accuracy: 0.5396 - val_loss: 1.3074 - val_accuracy: 0.4873\n",
            "Epoch 951/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2133 - accuracy: 0.5223 - val_loss: 1.3102 - val_accuracy: 0.4873\n",
            "Epoch 952/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2195 - accuracy: 0.5337 - val_loss: 1.3065 - val_accuracy: 0.4861\n",
            "Epoch 953/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2183 - accuracy: 0.5233 - val_loss: 1.3169 - val_accuracy: 0.4792\n",
            "Epoch 954/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2089 - accuracy: 0.5347 - val_loss: 1.3176 - val_accuracy: 0.4734\n",
            "Epoch 955/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2031 - accuracy: 0.5332 - val_loss: 1.3103 - val_accuracy: 0.4838\n",
            "Epoch 956/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2176 - accuracy: 0.5302 - val_loss: 1.3199 - val_accuracy: 0.4954\n",
            "Epoch 957/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.2138 - accuracy: 0.5282 - val_loss: 1.3265 - val_accuracy: 0.4792\n",
            "Epoch 958/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.2100 - accuracy: 0.5387 - val_loss: 1.3175 - val_accuracy: 0.4873\n",
            "Epoch 959/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1942 - accuracy: 0.5545 - val_loss: 1.3175 - val_accuracy: 0.4827\n",
            "Epoch 960/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2045 - accuracy: 0.5382 - val_loss: 1.3543 - val_accuracy: 0.4677\n",
            "Epoch 961/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2100 - accuracy: 0.5287 - val_loss: 1.3142 - val_accuracy: 0.4942\n",
            "Epoch 962/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2058 - accuracy: 0.5268 - val_loss: 1.3311 - val_accuracy: 0.4792\n",
            "Epoch 963/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2035 - accuracy: 0.5253 - val_loss: 1.3044 - val_accuracy: 0.4919\n",
            "Epoch 964/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2088 - accuracy: 0.5342 - val_loss: 1.3088 - val_accuracy: 0.4861\n",
            "Epoch 965/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.2063 - accuracy: 0.5401 - val_loss: 1.2997 - val_accuracy: 0.4815\n",
            "Epoch 966/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2048 - accuracy: 0.5273 - val_loss: 1.3013 - val_accuracy: 0.4908\n",
            "Epoch 967/1000\n",
            "127/127 [==============================] - 7s 59ms/step - loss: 1.1943 - accuracy: 0.5342 - val_loss: 1.3067 - val_accuracy: 0.4931\n",
            "Epoch 968/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1991 - accuracy: 0.5367 - val_loss: 1.3143 - val_accuracy: 0.4827\n",
            "Epoch 969/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2031 - accuracy: 0.5461 - val_loss: 1.3098 - val_accuracy: 0.4908\n",
            "Epoch 970/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2050 - accuracy: 0.5268 - val_loss: 1.3020 - val_accuracy: 0.4815\n",
            "Epoch 971/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2076 - accuracy: 0.5337 - val_loss: 1.3123 - val_accuracy: 0.4873\n",
            "Epoch 972/1000\n",
            "127/127 [==============================] - 7s 53ms/step - loss: 1.1972 - accuracy: 0.5347 - val_loss: 1.3060 - val_accuracy: 0.4838\n",
            "Epoch 973/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2038 - accuracy: 0.5372 - val_loss: 1.3021 - val_accuracy: 0.4908\n",
            "Epoch 974/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2029 - accuracy: 0.5317 - val_loss: 1.3116 - val_accuracy: 0.4965\n",
            "Epoch 975/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1942 - accuracy: 0.5406 - val_loss: 1.3242 - val_accuracy: 0.4781\n",
            "Epoch 976/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.1944 - accuracy: 0.5362 - val_loss: 1.3188 - val_accuracy: 0.4838\n",
            "Epoch 977/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2068 - accuracy: 0.5406 - val_loss: 1.3010 - val_accuracy: 0.4896\n",
            "Epoch 978/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.1937 - accuracy: 0.5426 - val_loss: 1.3092 - val_accuracy: 0.4758\n",
            "Epoch 979/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.2073 - accuracy: 0.5391 - val_loss: 1.3347 - val_accuracy: 0.4781\n",
            "Epoch 980/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.2110 - accuracy: 0.5342 - val_loss: 1.3083 - val_accuracy: 0.4861\n",
            "Epoch 981/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1935 - accuracy: 0.5352 - val_loss: 1.2986 - val_accuracy: 0.4861\n",
            "Epoch 982/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2115 - accuracy: 0.5347 - val_loss: 1.3048 - val_accuracy: 0.4908\n",
            "Epoch 983/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.1977 - accuracy: 0.5322 - val_loss: 1.3168 - val_accuracy: 0.4919\n",
            "Epoch 984/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.1934 - accuracy: 0.5362 - val_loss: 1.2972 - val_accuracy: 0.4908\n",
            "Epoch 985/1000\n",
            "127/127 [==============================] - 7s 58ms/step - loss: 1.2119 - accuracy: 0.5347 - val_loss: 1.3019 - val_accuracy: 0.4954\n",
            "Epoch 986/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2078 - accuracy: 0.5248 - val_loss: 1.3112 - val_accuracy: 0.4827\n",
            "Epoch 987/1000\n",
            "127/127 [==============================] - 7s 57ms/step - loss: 1.2066 - accuracy: 0.5352 - val_loss: 1.3008 - val_accuracy: 0.4954\n",
            "Epoch 988/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.1975 - accuracy: 0.5416 - val_loss: 1.3094 - val_accuracy: 0.4861\n",
            "Epoch 989/1000\n",
            "127/127 [==============================] - 9s 68ms/step - loss: 1.1980 - accuracy: 0.5367 - val_loss: 1.3096 - val_accuracy: 0.4919\n",
            "Epoch 990/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.2060 - accuracy: 0.5258 - val_loss: 1.3020 - val_accuracy: 0.4838\n",
            "Epoch 991/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.1933 - accuracy: 0.5436 - val_loss: 1.3034 - val_accuracy: 0.4919\n",
            "Epoch 992/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1824 - accuracy: 0.5367 - val_loss: 1.3333 - val_accuracy: 0.4711\n",
            "Epoch 993/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.1992 - accuracy: 0.5441 - val_loss: 1.3222 - val_accuracy: 0.4873\n",
            "Epoch 994/1000\n",
            "127/127 [==============================] - 8s 66ms/step - loss: 1.1940 - accuracy: 0.5401 - val_loss: 1.3089 - val_accuracy: 0.4827\n",
            "Epoch 995/1000\n",
            "127/127 [==============================] - 8s 63ms/step - loss: 1.1992 - accuracy: 0.5436 - val_loss: 1.3106 - val_accuracy: 0.4954\n",
            "Epoch 996/1000\n",
            "127/127 [==============================] - 8s 62ms/step - loss: 1.1887 - accuracy: 0.5382 - val_loss: 1.3008 - val_accuracy: 0.4919\n",
            "Epoch 997/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.1983 - accuracy: 0.5238 - val_loss: 1.2980 - val_accuracy: 0.4919\n",
            "Epoch 998/1000\n",
            "127/127 [==============================] - 8s 60ms/step - loss: 1.1875 - accuracy: 0.5391 - val_loss: 1.3020 - val_accuracy: 0.4850\n",
            "Epoch 999/1000\n",
            "127/127 [==============================] - 8s 59ms/step - loss: 1.1829 - accuracy: 0.5332 - val_loss: 1.2985 - val_accuracy: 0.4988\n",
            "Epoch 1000/1000\n",
            "127/127 [==============================] - 8s 61ms/step - loss: 1.1893 - accuracy: 0.5525 - val_loss: 1.3066 - val_accuracy: 0.4838\n",
            "28/28 - 0s - loss: 1.3066 - accuracy: 0.4838 - 455ms/epoch - 16ms/step\n",
            "LSTM model test accuracy:  0.4838337302207947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDaH3smvCfaB"
      },
      "source": [
        "####                                                                                THANK YOU !!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "SpeechRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}