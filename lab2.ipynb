{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.7.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "colab": {
      "name": "lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emilstahl97/Scalable-Machine-Learning-and-Deep-Learning-ID2223/blob/dev/lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaKRw_y60AN8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a288e7-99b8-407b-ea93-072307c103ae"
      },
      "source": [
        " import os\n",
        "\n",
        "!pip install pyspark\n",
        "!pip install --upgrade tensorflow_hub\n",
        "!pip install --upgrade tensorflow_text\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()\n"
      ],
      "id": "zaKRw_y60AN8",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.3 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.2\n",
            "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 60.8 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=8dc218affcbce12fbe7824f1eeb54e5a172c027a100bfbc22ebd53d27af3a920\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_hub) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eca01b13-a070-479d-aa33-75a05bfe0baa"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import functools\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "id": "eca01b13-a070-479d-aa33-75a05bfe0baa",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbUaf08DAsE_"
      },
      "source": [
        "****Mount notebook in your Google Drive****"
      ],
      "id": "gbUaf08DAsE_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83DfFbqfWHtX",
        "outputId": "c10cb4f1-87da-4d31-ffa3-9a82a3be56ad"
      },
      "source": [
        "# README - Execute this cell to mount the notebook in your google drive. \n",
        "# Exxdecute the cell and follow the link to sign and, paste the given key in the little text box. The credentials are only available for you. \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "os.mkdir(\"/content/drive/MyDrive/stsbenchmark\")\n",
        "os.chdir(\"/content/drive/MyDrive/stsbenchmark\")\n",
        "!git clone https://github.com/emilstahl97/stsbenchmark.git\n",
        "!git pull\n"
      ],
      "id": "83DfFbqfWHtX",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'stsbenchmark'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (8/8), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 8 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (8/8), done.\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnAlR7iaXGqc",
        "outputId": "136f45de-a7e2-46a0-a82b-cd70eb41d1e0"
      },
      "source": [
        "schema = StructType([\n",
        "    StructField(\"genre\", StringType(), True),\n",
        "    StructField(\"filename\", StringType(), True),\n",
        "    StructField(\"year\", StringType(), True),\n",
        "    StructField(\"year_id\", IntegerType(), True),\n",
        "    StructField(\"score\", FloatType(), True),\n",
        "    StructField(\"sentence1\", StringType(), True),\n",
        "    StructField(\"sentence2\", StringType(), True)])\n",
        "\n",
        "# get the datasets from drive\n",
        "train = spark.read.csv(\"/content/drive/MyDrive/stsbenchmark/stsbenchmark/sts-train.csv\", sep ='\\t', header=False, schema=schema)\n",
        "test = spark.read.csv(\"/content/drive/MyDrive/stsbenchmark/stsbenchmark/sts-test.csv\", sep ='\\t', header=False, schema=schema)\n",
        "dev = spark.read.csv(\"/content/drive/MyDrive/stsbenchmark/stsbenchmark/sts-dev.csv\", sep ='\\t', header=False, schema=schema)\n",
        "\n",
        "\n",
        "train.show()\n",
        "test.show()\n",
        "dev.show()"
      ],
      "id": "QnAlR7iaXGqc",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|        genre|filename|    year|year_id|score|           sentence1|           sentence2|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|main-captions|  MSRvid|2012test|      1|  5.0|A plane is taking...|An air plane is t...|\n",
            "|main-captions|  MSRvid|2012test|      4|  3.8|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|      5|  3.8|A man is spreadin...|A man is spreadin...|\n",
            "|main-captions|  MSRvid|2012test|      6|  2.6|Three men are pla...|Two men are playi...|\n",
            "|main-captions|  MSRvid|2012test|      9| 4.25|A man is playing ...|A man seated is p...|\n",
            "|main-captions|  MSRvid|2012test|     11| 4.25|Some men are figh...|Two men are fight...|\n",
            "|main-captions|  MSRvid|2012test|     12|  0.5|   A man is smoking.|   A man is skating.|\n",
            "|main-captions|  MSRvid|2012test|     13|  1.6|The man is playin...|The man is playin...|\n",
            "|main-captions|  MSRvid|2012test|     14|  2.2|A man is playing ...|A woman is playin...|\n",
            "|main-captions|  MSRvid|2012test|     16|  5.0|A person is throw...|A person throws a...|\n",
            "|main-captions|  MSRvid|2012test|     17|  4.2|The man hit the o...|The man spanked t...|\n",
            "|main-captions|  MSRvid|2012test|     18|  4.6|A woman picks up ...|A woman picks up ...|\n",
            "|main-captions|  MSRvid|2012test|     19|3.867|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     20|4.667|A person is foldi...|Someone is foldin...|\n",
            "|main-captions|  MSRvid|2012test|     21|1.667|A man is running ...|A panda dog is ru...|\n",
            "|main-captions|  MSRvid|2012test|     22| 3.75|A dog is trying t...|A dog is trying t...|\n",
            "|main-captions|  MSRvid|2012test|     25|  5.0|The polar bear is...|A polar bear is s...|\n",
            "|main-captions|  MSRvid|2012test|     26|  0.5| A woman is writing.|A woman is swimming.|\n",
            "|main-captions|  MSRvid|2012test|     28|  3.8|A cat is rubbing ...|A cat is rubbing ...|\n",
            "|main-captions|  MSRvid|2012test|     29|  5.0|The man is riding...|A man is riding o...|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|        genre|filename|    year|year_id|score|           sentence1|           sentence2|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|main-captions|  MSRvid|2012test|     24|  2.5|A girl is styling...|A girl is brushin...|\n",
            "|main-captions|  MSRvid|2012test|     33|  3.6|A group of men pl...|A group of boys a...|\n",
            "|main-captions|  MSRvid|2012test|     45|  5.0|One woman is meas...|A woman measures ...|\n",
            "|main-captions|  MSRvid|2012test|     63|  4.2|A man is cutting ...|A man is slicing ...|\n",
            "|main-captions|  MSRvid|2012test|     66|  1.5|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     74|  1.8|A woman is cuttin...|A woman is cuttin...|\n",
            "|main-captions|  MSRvid|2012test|     76|  3.5|A man is riding a...|A man is riding a...|\n",
            "|main-captions|  MSRvid|2012test|     82|  2.2|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     92|  2.2|A man is playing ...|A lady is playing...|\n",
            "|main-captions|  MSRvid|2012test|     95|1.714|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     96|1.714|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|    100|  5.0|A man is cutting ...|A man cuts an onion.|\n",
            "|main-captions|  MSRvid|2012test|    103|  0.6|   A man is cycling.|   A man is talking.|\n",
            "|main-captions|  MSRvid|2012test|    107|  4.4|A man is slicing ...|A man is cutting ...|\n",
            "|main-captions|  MSRvid|2012test|    124|  2.0|A man is slicing ...|A man is slicing ...|\n",
            "|main-captions|  MSRvid|2012test|    127|  1.8|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|    128|  4.4|A baby panda goes...|A panda slides do...|\n",
            "|main-captions|  MSRvid|2012test|    134|  3.6|A man is singing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|    137|  3.6|A man attacks a w...|A man slaps a woman.|\n",
            "|main-captions|  MSRvid|2012test|    139|  1.2|A man is driving ...|A man is riding a...|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|        genre|filename|    year|year_id|score|           sentence1|           sentence2|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "|main-captions|  MSRvid|2012test|      0|  5.0|A man with a hard...|A man wearing a h...|\n",
            "|main-captions|  MSRvid|2012test|      2| 4.75|A young child is ...|A child is riding...|\n",
            "|main-captions|  MSRvid|2012test|      3|  5.0|A man is feeding ...|The man is feedin...|\n",
            "|main-captions|  MSRvid|2012test|      7|  2.4|A woman is playin...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|      8| 2.75|A woman is playin...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     10|2.615|A woman is cuttin...|A man is cutting ...|\n",
            "|main-captions|  MSRvid|2012test|     15|  5.0|A man is erasing ...|The man is erasin...|\n",
            "|main-captions|  MSRvid|2012test|     23|2.333|A woman is carryi...|A woman is carryi...|\n",
            "|main-captions|  MSRvid|2012test|     27| 3.75|Three men are pla...|Three men are on ...|\n",
            "|main-captions|  MSRvid|2012test|     36|  5.0|A woman peels a p...|A woman is peelin...|\n",
            "|main-captions|  MSRvid|2012test|     37|  3.2|People are playin...|Men are playing c...|\n",
            "|main-captions|  MSRvid|2012test|     39|1.583|A man is playing ...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     41|  5.0|The cougar is cha...|A cougar is chasi...|\n",
            "|main-captions|  MSRvid|2012test|     43|  5.0|The man cut down ...|A man chops down ...|\n",
            "|main-captions|  MSRvid|2012test|     49|4.909|The man is playin...|A man is playing ...|\n",
            "|main-captions|  MSRvid|2012test|     51|  0.8|A man is finding ...|A woman is slicin...|\n",
            "|main-captions|  MSRvid|2012test|     60|  2.4|The girl sang int...|The lady sang int...|\n",
            "|main-captions|  MSRvid|2012test|     67|  5.0|A man is climbing...|A man climbs a rope.|\n",
            "|main-captions|  MSRvid|2012test|     79|  4.0|Kittens are eatin...|Kittens are eatin...|\n",
            "|main-captions|  MSRvid|2012test|     88|0.636|  A man is speaking.|  A man is spitting.|\n",
            "+-------------+--------+--------+-------+-----+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-GlOPMDaW7a"
      },
      "source": [
        "## **Normalize score column of each dataset**"
      ],
      "id": "X-GlOPMDaW7a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Tru6bwEaSzu",
        "outputId": "c3fc6da0-15df-4b28-8aa6-70f447ce2852"
      },
      "source": [
        "train = train.withColumn(\"score\", col(\"score\")/2.5-1)\n",
        "test = test.withColumn(\"score\", col(\"score\")/2.5-1)\n",
        "dev = dev.withColumn(\"score\", col(\"score\")/2.5-1)\n",
        "\n",
        "dev.select(\"score\").describe().show()"
      ],
      "id": "6Tru6bwEaSzu",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+\n",
            "|summary|               score|\n",
            "+-------+--------------------+\n",
            "|  count|                1500|\n",
            "|   mean|-0.05443697837591158|\n",
            "| stddev|  0.6001942581590352|\n",
            "|    min|                -1.0|\n",
            "|    max|                 1.0|\n",
            "+-------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zQpGcFQatbQ",
        "outputId": "c5119eee-1519-4683-f00d-1ac7cbd54e40"
      },
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "\n",
        "text_preprocessed = preprocessing_layer(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "id": "8zQpGcFQatbQ",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_word_ids', 'input_mask', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZytjcOpa3O9",
        "outputId": "e7795309-41d1-46a2-b4cf-810b12bcab3c"
      },
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "\n",
        "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "\n",
        "bert_results = encoder(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"][0].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "id": "OZytjcOpa3O9",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.7626293   0.9928098  -0.18611859  0.36673865  0.15233742  0.6550452\n",
            "  0.9681154  -0.94862705  0.00216148 -0.9877732   0.0684269  -0.9763061 ]\n",
            "Sequence Outputs Shape:(128, 512)\n",
            "Sequence Outputs Values:[[-0.28946307  0.34321287  0.33231482 ...  0.21300784  0.7102064\n",
            "  -0.05771124]\n",
            " [-0.28742093  0.3198104  -0.2301862  ...  0.58455014 -0.21329764\n",
            "   0.7269209 ]\n",
            " [-0.6615701   0.6887682  -0.8743294  ...  0.10877228 -0.26173192\n",
            "   0.4785537 ]\n",
            " ...\n",
            " [-0.22561091 -0.28925657 -0.07064448 ...  0.47566032  0.8327713\n",
            "   0.40025362]\n",
            " [-0.298242   -0.27473173 -0.05450522 ...  0.48849788  1.0955355\n",
            "   0.18163413]\n",
            " [-0.44378197  0.00930735  0.07223716 ...  0.172901    1.1833245\n",
            "   0.07898018]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPUFsaFUbDT6"
      },
      "source": [
        "**Input Layer**"
      ],
      "id": "NPUFsaFUbDT6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miFa33X1bB-v"
      },
      "source": [
        "text_input_u = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text_u')\n",
        "text_input_v = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text_v')"
      ],
      "id": "miFa33X1bB-v",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rQrrCB0bMoT"
      },
      "source": [
        "**Preprocessing Layer**"
      ],
      "id": "8rQrrCB0bMoT"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-mf3rTybP3m"
      },
      "source": [
        "preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing_u')\n",
        "encoder_input_u = preprocessing_layer(text_input_u)\n",
        "preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing_v')\n",
        "encoder_input_v = preprocessing_layer(text_input_v)"
      ],
      "id": "1-mf3rTybP3m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqJ3praxbaPR"
      },
      "source": [
        "**BERT encoder layer**"
      ],
      "id": "aqJ3praxbaPR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhBvcR49bf1B"
      },
      "source": [
        "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder_u')\n",
        "outputs_u = encoder(encoder_input_u)\n",
        "encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder_v')\n",
        "outputs_v = encoder(encoder_input_v)"
      ],
      "id": "IhBvcR49bf1B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezr3JX2fbl7j"
      },
      "source": [
        "**Pooled Output**"
      ],
      "id": "ezr3JX2fbl7j"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6GHTPoDbqyK"
      },
      "source": [
        "avg_pool_2d  = tf.keras.layers.AveragePooling2D(pool_size=(128, 1), strides=(128, 1), name='pooling_u')\n",
        "sequence_output = outputs_u[\"sequence_output\"][0]\n",
        "sequence_output = tf.reshape(sequence_output, [1, 128, 512, 1])\n",
        "pooled_u = avg_pool_2d(sequence_output)[0][0]\n",
        "\n",
        "avg_pool_2d  = tf.keras.layers.AveragePooling2D(pool_size=(128, 1), strides=(128, 1), name='pooling_v')\n",
        "sequence_output = outputs_v[\"sequence_output\"][0]\n",
        "sequence_output = tf.reshape(sequence_output, [1, 128, 512, 1])\n",
        "pooled_v = avg_pool_2d(sequence_output)[0][0]"
      ],
      "id": "x6GHTPoDbqyK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O14T0Z3sb4kP"
      },
      "source": [
        "**Output Layer**"
      ],
      "id": "O14T0Z3sb4kP"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH5qTOuFbz-Z"
      },
      "source": [
        "print(pooled_u.shape)\n",
        "cos_distance = tf.keras.layers.Dot(axes = 1, normalize=True)([tf.reshape(pooled_u, [1, 512, 1]), tf.reshape(pooled_v, [1, 512, 1])]) # where cos (x)\n",
        "print(cos_distance)\n",
        "cos_distance = tf.keras.layers.Reshape((1,))(cos_distance)\n",
        "final = tf.keras.layers.Lambda(lambda x: 1-x)(cos_distance)\n",
        "\n",
        "#print(output_concat[:,1].shape)\n",
        "\n",
        "#cosine_loss = tf.keras.losses.CosineSimilarity(axis=-1)\n",
        "#final = cosine_loss(output_concat[:,0], output_concat[:,1])\n",
        "\n",
        "print(final.shape)"
      ],
      "id": "lH5qTOuFbz-Z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGAvajVocCiN"
      },
      "source": [
        "**Model**"
      ],
      "id": "UGAvajVocCiN"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7Hewm1ocCM3"
      },
      "source": [
        "model = tf.keras.Model(inputs=[text_input_u, text_input_v], outputs=[final])\n",
        "\n",
        "tf.keras.utils.plot_model(model)\n",
        "print(model)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# https://www.sbert.net/docs/training/overview.html"
      ],
      "id": "-7Hewm1ocCM3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGRukww0chyA"
      },
      "source": [
        "**Compiling Model**"
      ],
      "id": "VGRukww0chyA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-zr5_ZGcpk1"
      },
      "source": [
        "optimizer = tf.optimizers.Adam(0.001)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "df = test.select(\"sentence1\",\"sentence2\",\"score\").toPandas()\n",
        "\n",
        "print(df.isna().sum())\n",
        "df = df.fillna('')\n",
        "\n",
        "#import numpy as np\n",
        "#df[\"score\"] = np.asarray(df[\"score\"]).astype(np.float32)\n",
        "#print(list(df[\"score\"]))\n",
        "\n",
        "results = model.evaluate([df[\"sentence1\"],df[\"sentence2\"]],df[\"score\"])\n",
        "print(\"Results: \", results)"
      ],
      "id": "A-zr5_ZGcpk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUfdVEYvcwah"
      },
      "source": [
        "print([df[\"sentence1\"][1],df[\"sentence1\"][1]])\n",
        "print(df[\"score\"][1])\n",
        "print(model.predict([df[\"sentence1\"][1:2],df[\"sentence1\"][1:2]]))\n"
      ],
      "id": "vUfdVEYvcwah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcTIuxprc0qp"
      },
      "source": [
        "**Train**"
      ],
      "id": "OcTIuxprc0qp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGBPZfHec3k5"
      },
      "source": [
        "train.show(5)\n",
        "model.fit()"
      ],
      "id": "aGBPZfHec3k5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kV1y3_mdAQG"
      },
      "source": [
        "**Prediction**"
      ],
      "id": "-kV1y3_mdAQG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcCR8PBvdE8t"
      },
      "source": [
        "classifications = model.predict()"
      ],
      "id": "IcCR8PBvdE8t",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y1i4BoCdT8s"
      },
      "source": [
        "**Evaluation**"
      ],
      "id": "6y1i4BoCdT8s"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aHvmPrWdEzA"
      },
      "source": [
        "model.evaluate()"
      ],
      "id": "1aHvmPrWdEzA",
      "execution_count": null,
      "outputs": []
    }
  ]
}